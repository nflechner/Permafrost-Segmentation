{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnadja-flechner\u001b[0m (\u001b[33mnadjaflechner\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nadjaflechner/palsa_seg/4dim_regr_CAM/wandb/run-20240520_082153-mj5hglaa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nadjaflechner/VGG_CAMs/runs/mj5hglaa/workspace' target=\"_blank\">soft-sound-38</a></strong> to <a href='https://wandb.ai/nadjaflechner/VGG_CAMs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nadjaflechner/VGG_CAMs' target=\"_blank\">https://wandb.ai/nadjaflechner/VGG_CAMs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nadjaflechner/VGG_CAMs/runs/mj5hglaa/workspace' target=\"_blank\">https://wandb.ai/nadjaflechner/VGG_CAMs/runs/mj5hglaa/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "############\n",
    "# Imports #\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from torchvision import models, transforms\n",
    "from custom_model import model_4D\n",
    "from utils import ImageDataset, SaveFeatures, accuracy, imshow_transform\n",
    "from torch.autograd import Variable\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imshow\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt \n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "###################\n",
    "# Hyperparameters #\n",
    "\n",
    "n_samples = 25000\n",
    "n_samples_train = int(round(n_samples*0.8))\n",
    "batch_size = 40\n",
    "current_computer =  \"ubuntu\" # \"macbook\" \n",
    "layers_to_freeze = 41\n",
    "lr = 0.00001\n",
    "weight_decay=0.04\n",
    "num_epochs = 10\n",
    "im_size = 100\n",
    "min_palsa_positive_samples = 10\n",
    "\n",
    "\n",
    "##########################\n",
    "# log hyperparams to w&b #\n",
    "\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"VGG_CAMs\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"epochs\": num_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"n_samples\": n_samples,\n",
    "        \"layers_to_freeze\": layers_to_freeze,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"im_size\": im_size,\n",
    "        \"min_palsa_positive_samples\": min_palsa_positive_samples\n",
    "    },\n",
    "    tags = [\"MSELoss\", \"regressopm\", \"4D\", \"LRscheduler\"]\n",
    ")\n",
    "\n",
    "#############\n",
    "# Load data #\n",
    "\n",
    "if current_computer == \"ubuntu\":\n",
    "    hs_dir = '/home/nadjaflechner/Palsa_data/cropped_hillshade/hs'\n",
    "    RGB_dir = '/home/nadjaflechner/Palsa_data/cropped_hillshade/rgb'\n",
    "    labels_file = '/home/nadjaflechner/Palsa_data/cropped_hillshade/palsa_labels.csv'\n",
    "elif current_computer == \"macbook\":\n",
    "    hs_dir = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/hs'\n",
    "    RGB_dir = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/rgb'\n",
    "    labels_file = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/palsa_labels.csv'\n",
    "\n",
    "# Load the labels from the CSV file\n",
    "if min_palsa_positive_samples > 0:\n",
    "    labels_df = pd.read_csv(labels_file, index_col=0)\n",
    "    drop_range = labels_df[ (labels_df['palsa_percentage'] > 0) & (labels_df['palsa_percentage'] <= 10) ].index\n",
    "    labels_df.drop(drop_range, inplace=True)\n",
    "    labels_df = labels_df.head(n_samples)\n",
    "else: \n",
    "    labels_df = pd.read_csv(labels_file, index_col=0).head(n_samples)\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df = labels_df.head(n_samples_train)\n",
    "val_df = labels_df.drop(train_df.index)\n",
    "\n",
    "# Create the datasets and data loaders\n",
    "train_dataset = ImageDataset(hs_dir, RGB_dir, train_df)\n",
    "val_dataset = ImageDataset(hs_dir, RGB_dir, val_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Define model \n",
    "\n",
    "model = model_4D()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay) \n",
    "# scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.3, total_iters=10)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.92)\n",
    "loss_function = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  1\n",
      "EPOCH:  2\n",
      "EPOCH:  3\n",
      "EPOCH:  4\n",
      "EPOCH:  5\n",
      "EPOCH:  6\n",
      "EPOCH:  7\n",
      "EPOCH:  8\n",
      "EPOCH:  9\n",
      "EPOCH:  10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Artifact model>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################\n",
    "# Training loop #\n",
    "\n",
    "# adapted from https://github.com/tony-mtz/CAM/blob/master/network/net.py\n",
    "\n",
    "mean_train_losses = []\n",
    "mean_val_losses = []\n",
    "\n",
    "mean_train_acc = []\n",
    "mean_val_acc = []\n",
    "\n",
    "min_val_loss = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('EPOCH: ',epoch+1)\n",
    "\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    train_batch_count = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):     \n",
    "\n",
    "        # load images and labels \n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels.float()).to(device)\n",
    "\n",
    "        # train batch   \n",
    "        outputs = model(images)   \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, labels.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "\n",
    "        # calculate loss and accuracy\n",
    "        # train_acc.append(accuracy(outputs.squeeze(), labels.float()))\n",
    "        running_loss += loss.item()\n",
    "        train_batch_count += 1\n",
    "   \n",
    "    model.eval()\n",
    "    val_batch_count = 0\n",
    "    val_running_loss = 0.0\n",
    "    model.to(device)\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(val_loader):     \n",
    "        # inference   \n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels.float()).to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = loss_function(outputs, labels.unsqueeze(1))\n",
    "\n",
    "        # val_acc.append(accuracy(outputs.squeeze(), labels.float()))\n",
    "        val_running_loss += loss.item()\n",
    "        val_batch_count +=1\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # update losses and accuracies \n",
    "\n",
    "    # mean_train_acc.append(np.mean(train_acc))\n",
    "    # # mean_val_acc.append(np.mean(val_acc))\n",
    "    mean_train_losses.append(running_loss/train_batch_count)\n",
    "    mean_val_losses.append(val_running_loss/val_batch_count)\n",
    "\n",
    "    # # wandb.log({\"train_accuracy\": np.mean(train_acc)})\n",
    "    # # wandb.log({\"val_accuracy\": np.mean(val_acc)})\n",
    "    wandb.log({\"train_loss\": running_loss/train_batch_count})\n",
    "    wandb.log({\"val_loss\": val_running_loss/val_batch_count})\n",
    "\n",
    "    if val_running_loss/val_batch_count < min_val_loss:\n",
    "        best_model = model.state_dict()\n",
    "        min_val_loss = val_running_loss/val_batch_count\n",
    "\n",
    "torch.save(best_model, '/home/nadjaflechner/models/model.pth')\n",
    "artifact = wandb.Artifact('model', type='model')\n",
    "artifact.add_file('/home/nadjaflechner/models/model.pth')\n",
    "run.log_artifact(artifact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.68441790e-02  6.15850389e-02  4.63015288e-02  4.59083207e-02\n",
      "   4.89508957e-02  4.81681675e-02  4.76713032e-02  4.84059937e-02\n",
      "   4.88239229e-02  4.93103750e-02  5.12048975e-02  5.07308468e-02\n",
      "   4.70214039e-02  5.01411334e-02  4.71722707e-02  4.22593914e-02\n",
      "   3.25649716e-02  2.03466807e-02  8.19651969e-03 -3.69595177e-03\n",
      "  -2.80594826e-03 -8.55380390e-03 -7.81029239e-02 -6.37277186e-01\n",
      "   7.24210858e-01]\n",
      " [ 6.46350235e-02  8.54820907e-02  7.58716315e-02  7.86296427e-02\n",
      "   8.33183080e-02  8.63639191e-02  8.67269039e-02  8.53420794e-02\n",
      "   8.36532637e-02  8.47506225e-02  8.43601599e-02  8.24434310e-02\n",
      "   8.22383389e-02  8.23937133e-02  7.94981271e-02  6.98833466e-02\n",
      "   5.99360764e-02  4.12383080e-02  3.48162502e-02  2.96705384e-02\n",
      "   4.33967859e-02  5.68867326e-02  5.20435721e-02 -8.29995692e-01\n",
      "   1.59058428e+00]\n",
      " [ 6.47295862e-02  7.62637854e-02  5.26202284e-02  4.24372889e-02\n",
      "   4.21409495e-02  4.33334038e-02  4.82849143e-02  5.00138216e-02\n",
      "   5.32087572e-02  5.59241772e-02  5.48194237e-02  5.14155515e-02\n",
      "   5.01649380e-02  5.20894192e-02  4.32600118e-02  3.46298292e-02\n",
      "   3.08625028e-02  2.27496549e-02  3.40451747e-02  3.27061675e-02\n",
      "   3.67208347e-02  4.41721529e-02  3.38105187e-02 -1.04695392e+00\n",
      "   1.86142480e+00]\n",
      " [ 7.57794231e-02  8.09075534e-02  5.37137836e-02  3.82123627e-02\n",
      "   3.43370326e-02  3.76626290e-02  4.28001955e-02  5.02261929e-02\n",
      "   5.68071939e-02  6.12667724e-02  6.26242757e-02  5.90625070e-02\n",
      "   5.84247373e-02  5.36409616e-02  4.29842733e-02  2.96677481e-02\n",
      "   2.77845655e-02  2.11392790e-02  2.78313011e-02  2.57708449e-02\n",
      "   2.73693744e-02  3.13519388e-02  1.64629631e-02 -1.08890355e+00\n",
      "   1.88959837e+00]\n",
      " [ 6.97666481e-02  6.76323399e-02  3.65611240e-02  1.77091360e-02\n",
      "   1.29057784e-02  1.41332159e-02  2.61282288e-02  3.82845514e-02\n",
      "   4.66277003e-02  5.40248863e-02  5.52691184e-02  5.56757040e-02\n",
      "   5.80131561e-02  5.65423593e-02  5.01680598e-02  3.95175852e-02\n",
      "   3.06001268e-02  1.60296205e-02  6.72933040e-03  2.79220659e-03\n",
      "   5.21945255e-03  1.21055897e-02  1.46474196e-02 -1.09333742e+00\n",
      "   1.90339458e+00]\n",
      " [ 6.47178814e-02  5.79103902e-02  2.64388081e-02  5.45624085e-03\n",
      "  -1.24293962e-03 -2.21757591e-03  1.12609984e-02  2.39748731e-02\n",
      "   3.65460068e-02  4.39800918e-02  4.65113185e-02  4.79799584e-02\n",
      "   5.10154404e-02  5.58174551e-02  5.63167892e-02  5.37054241e-02\n",
      "   4.75368500e-02  2.82471776e-02  1.04383826e-02 -1.82850217e-03\n",
      "  -1.99292460e-03  3.08643468e-03  6.49284013e-03 -1.10350752e+00\n",
      "   1.90883183e+00]\n",
      " [ 6.15086481e-02  4.80990484e-02  1.23737101e-02 -6.08618930e-03\n",
      "  -1.10119414e-02 -5.98315801e-03  6.29383232e-03  2.02807039e-02\n",
      "   3.22015472e-02  3.93034294e-02  4.27680202e-02  4.75858003e-02\n",
      "   5.24438657e-02  6.02840632e-02  6.02922067e-02  6.11009113e-02\n",
      "   5.32894582e-02  3.57535481e-02  9.88495070e-03 -8.16818140e-03\n",
      "  -1.28406696e-02 -3.86385201e-03  7.83156510e-03 -1.08149111e+00\n",
      "   1.90818262e+00]\n",
      " [ 6.38419911e-02  4.89506796e-02  9.30971373e-03 -9.97307152e-03\n",
      "  -9.26876813e-03  1.07188942e-04  1.26425605e-02  2.18368173e-02\n",
      "   2.93813646e-02  3.03829219e-02  2.89527029e-02  3.21494192e-02\n",
      "   4.08678949e-02  5.31052724e-02  5.91932945e-02  6.14015162e-02\n",
      "   5.46623394e-02  4.30252217e-02  2.24038400e-02  2.60864384e-03\n",
      "  -1.35780014e-02 -9.87209845e-03 -2.14236462e-03 -1.06489015e+00\n",
      "   1.86394823e+00]\n",
      " [ 6.53746128e-02  5.40598109e-02  1.50218420e-02 -1.52372732e-03\n",
      "   4.29544691e-03  2.20340881e-02  3.43554839e-02  4.00328860e-02\n",
      "   3.67444754e-02  2.83990297e-02  1.84515994e-02  1.87328644e-02\n",
      "   2.88647413e-02  4.48421352e-02  5.45525141e-02  5.32028861e-02\n",
      "   4.79678437e-02  4.13461179e-02  2.71656644e-02  1.51349595e-02\n",
      "   7.19452859e-04  1.06771709e-03  1.87706761e-03 -1.05024815e+00\n",
      "   1.82551754e+00]\n",
      " [ 7.06305876e-02  5.97366020e-02  2.63098180e-02  1.09375222e-02\n",
      "   2.18027961e-02  4.32172269e-02  5.80699518e-02  5.73634282e-02\n",
      "   4.51019779e-02  2.88158096e-02  1.40249217e-02  1.11481100e-02\n",
      "   2.46620942e-02  3.75239775e-02  4.51561995e-02  4.47406471e-02\n",
      "   4.24074046e-02  3.93619314e-02  3.23937759e-02  2.53498405e-02\n",
      "   1.64919831e-02  1.42956311e-02  8.55981372e-03 -1.05481911e+00\n",
      "   1.81625700e+00]\n",
      " [ 7.30684102e-02  6.71730563e-02  3.65214273e-02  2.35044267e-02\n",
      "   3.38924229e-02  5.32085672e-02  6.13628328e-02  6.06158748e-02\n",
      "   5.09496257e-02  3.48884128e-02  1.53611097e-02  9.58713703e-03\n",
      "   1.81013923e-02  3.00773941e-02  3.77684757e-02  3.87473330e-02\n",
      "   4.11736891e-02  4.33347449e-02  3.96265760e-02  3.55456769e-02\n",
      "   2.73690969e-02  2.90399157e-02  2.08391771e-02 -1.05561185e+00\n",
      "   1.84562266e+00]\n",
      " [ 7.53046647e-02  7.48937503e-02  4.46120203e-02  3.43404785e-02\n",
      "   4.32205237e-02  5.33865876e-02  5.75310141e-02  6.04034550e-02\n",
      "   5.41756488e-02  3.62562761e-02  1.91076137e-02  1.25070810e-02\n",
      "   2.17579138e-02  3.15274894e-02  3.80446687e-02  3.77237499e-02\n",
      "   4.27203961e-02  4.58306633e-02  4.25411388e-02  4.24624309e-02\n",
      "   3.79404053e-02  3.92209888e-02  2.92527229e-02 -1.06643724e+00\n",
      "   1.87462258e+00]\n",
      " [ 7.78359398e-02  8.22037905e-02  5.40111698e-02  4.33407277e-02\n",
      "   4.77931574e-02  4.70764711e-02  4.67863865e-02  5.43892980e-02\n",
      "   4.95984219e-02  3.96850258e-02  2.64708996e-02  2.24742088e-02\n",
      "   3.36309522e-02  4.04658802e-02  4.17932793e-02  4.03783508e-02\n",
      "   4.21373770e-02  4.43216190e-02  4.02270891e-02  3.98603901e-02\n",
      "   3.58921550e-02  3.96622084e-02  3.05496436e-02 -1.08324122e+00\n",
      "   1.89538777e+00]\n",
      " [ 7.90788159e-02  8.27913135e-02  5.94794452e-02  4.86810021e-02\n",
      "   4.52972800e-02  3.91077772e-02  3.90581414e-02  4.65249009e-02\n",
      "   4.76868376e-02  4.35614549e-02  3.57107669e-02  3.46730314e-02\n",
      "   4.48182337e-02  4.92569618e-02  4.89188693e-02  4.40931469e-02\n",
      "   4.48267348e-02  4.47274111e-02  3.76972184e-02  3.41842026e-02\n",
      "   3.13082263e-02  3.43074650e-02  2.58390121e-02 -1.09363949e+00\n",
      "   1.92350328e+00]\n",
      " [ 7.52292722e-02  8.50658119e-02  6.38424754e-02  5.17660603e-02\n",
      "   4.60161231e-02  3.31070311e-02  2.81968489e-02  3.70526873e-02\n",
      "   4.26040217e-02  3.97936404e-02  3.57234031e-02  3.86575013e-02\n",
      "   4.76018973e-02  5.42879030e-02  5.11461049e-02  4.64995541e-02\n",
      "   4.51856218e-02  4.11036611e-02  3.33903134e-02  3.03117465e-02\n",
      "   2.55620554e-02  3.19331661e-02  3.07425149e-02 -1.10625339e+00\n",
      "   1.94660616e+00]\n",
      " [ 6.44297376e-02  8.19493234e-02  6.53884858e-02  5.89433908e-02\n",
      "   5.03129400e-02  3.60958055e-02  2.66995691e-02  3.25930938e-02\n",
      "   3.41379605e-02  3.23620737e-02  2.79922932e-02  3.48143168e-02\n",
      "   4.50078100e-02  5.10104373e-02  5.00973575e-02  4.37517203e-02\n",
      "   3.82157490e-02  2.93947775e-02  2.37858333e-02  2.21029520e-02\n",
      "   1.47189619e-02  2.49988139e-02  1.88187547e-02 -1.13013840e+00\n",
      "   1.94585717e+00]\n",
      " [ 5.70883676e-02  7.11274296e-02  6.94017261e-02  6.06453232e-02\n",
      "   5.12394495e-02  3.87863442e-02  3.19509357e-02  3.44122611e-02\n",
      "   3.37770097e-02  3.31090875e-02  2.54323762e-02  2.46451087e-02\n",
      "   2.30539907e-02  2.88003366e-02  3.83948497e-02  3.91819291e-02\n",
      "   3.72055247e-02  3.44895236e-02  3.46409194e-02  4.16112207e-02\n",
      "   4.74824496e-02  4.82080653e-02  3.19324434e-02 -1.11502361e+00\n",
      "   1.95751953e+00]\n",
      " [ 6.63110837e-02  7.63679072e-02  6.14740923e-02  4.61901762e-02\n",
      "   3.98693047e-02  3.46169285e-02  3.04505825e-02  3.53829376e-02\n",
      "   3.32444161e-02  3.42669860e-02  2.53753792e-02  2.80101765e-02\n",
      "   3.47577147e-02  4.58525047e-02  5.43022752e-02  5.35521507e-02\n",
      "   5.70166297e-02  6.06013164e-02  6.35613054e-02  6.94017857e-02\n",
      "   6.50476813e-02  6.31531700e-02  3.95377204e-02 -1.08851898e+00\n",
      "   1.95653486e+00]\n",
      " [ 8.17371160e-02  8.61969292e-02  6.73596412e-02  4.92677689e-02\n",
      "   4.00192328e-02  3.01305316e-02  1.70177054e-02  1.57821085e-02\n",
      "   1.66414492e-02  3.16580348e-02  3.58113647e-02  4.84156087e-02\n",
      "   5.93703464e-02  6.47282749e-02  6.81662560e-02  6.36972263e-02\n",
      "   5.92553020e-02  5.36425784e-02  5.04473448e-02  5.04287481e-02\n",
      "   4.91645560e-02  5.76614067e-02  3.32157351e-02 -1.08225429e+00\n",
      "   1.92485976e+00]\n",
      " [ 7.80584067e-02  8.26937929e-02  6.77867532e-02  5.56133986e-02\n",
      "   4.17250581e-02  1.97226107e-02 -3.30995559e-03  4.29887732e-04\n",
      "   1.62930675e-02  4.68148552e-02  5.68362325e-02  5.93821928e-02\n",
      "   5.48938885e-02  5.00264801e-02  5.19417785e-02  4.88374904e-02\n",
      "   4.81243730e-02  4.72453125e-02  4.69597727e-02  4.91835549e-02\n",
      "   4.80192117e-02  5.41971922e-02  4.05434743e-02 -1.07241213e+00\n",
      "   1.90421236e+00]\n",
      " [ 7.40717277e-02  7.58993551e-02  5.85905127e-02  5.22423238e-02\n",
      "   4.96872552e-02  4.11690176e-02  3.32333110e-02  4.70552519e-02\n",
      "   5.62458485e-02  6.28200546e-02  5.53321913e-02  4.61403057e-02\n",
      "   4.19589803e-02  4.20866385e-02  4.61715162e-02  4.71055917e-02\n",
      "   4.22431789e-02  3.88192497e-02  4.05190289e-02  4.89249900e-02\n",
      "   5.12715057e-02  5.59657253e-02  3.77380364e-02 -1.07650292e+00\n",
      "   1.89208531e+00]\n",
      " [ 6.06838316e-02  7.90418833e-02  6.20828383e-02  5.52917309e-02\n",
      "   5.46309724e-02  5.67190833e-02  5.86609393e-02  6.35145009e-02\n",
      "   5.90277016e-02  5.44716865e-02  4.41540368e-02  4.07193042e-02\n",
      "   4.15588617e-02  5.01374938e-02  5.48813120e-02  5.34340180e-02\n",
      "   4.98140156e-02  4.43943515e-02  4.97340634e-02  6.01766184e-02\n",
      "   6.17825724e-02  7.03467950e-02  7.40312189e-02 -9.88575757e-01\n",
      "   1.91405952e+00]\n",
      " [-1.48296952e-01 -2.68325627e-01 -3.20107698e-01 -3.36388975e-01\n",
      "  -3.47783059e-01 -3.47099692e-01 -3.46229643e-01 -3.42205048e-01\n",
      "  -3.42041165e-01 -3.36841822e-01 -3.41710508e-01 -3.48631948e-01\n",
      "  -3.52278650e-01 -3.42318922e-01 -3.38905662e-01 -3.48039776e-01\n",
      "  -3.55431914e-01 -3.58067930e-01 -3.48698348e-01 -3.33893806e-01\n",
      "  -3.34617257e-01 -3.26212466e-01 -2.76986867e-01 -1.34401345e+00\n",
      "   1.58591974e+00]\n",
      " [-1.05334771e+00 -1.58303761e+00 -1.76268256e+00 -1.81302607e+00\n",
      "  -1.85599434e+00 -1.87441301e+00 -1.86964071e+00 -1.85554254e+00\n",
      "  -1.84133291e+00 -1.83150387e+00 -1.84063864e+00 -1.86232305e+00\n",
      "  -1.87841582e+00 -1.86477685e+00 -1.85294044e+00 -1.86908412e+00\n",
      "  -1.89176869e+00 -1.90861273e+00 -1.89320982e+00 -1.86353266e+00\n",
      "  -1.84581757e+00 -1.83952212e+00 -1.85372531e+00 -2.53531718e+00\n",
      "   5.76518774e-01]\n",
      " [ 2.20514393e+00  3.78161740e+00  4.34700584e+00  4.43577194e+00\n",
      "   4.51436472e+00  4.60474157e+00  4.62121487e+00  4.57099104e+00\n",
      "   4.52467155e+00  4.51041698e+00  4.51651716e+00  4.55208492e+00\n",
      "   4.59420586e+00  4.61059093e+00  4.59094524e+00  4.58492899e+00\n",
      "   4.64141703e+00  4.68833208e+00  4.68232155e+00  4.62398767e+00\n",
      "   4.55683708e+00  4.56573439e+00  4.58307981e+00  3.57610750e+00\n",
      "   3.56249142e+00]] (25, 25)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####################\n",
    "# generating CAMs #\n",
    "\n",
    "#change batch size to 1 to grab one image at a time\n",
    "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, \n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "# Load best model to produce CAMs with\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "# Save 10 palsa images\n",
    "# palsa_imgs = 0\n",
    "# for palsa_cam in range(100):\n",
    "\n",
    "im, lab = next(iter(valid_loader))\n",
    "\n",
    "#get the last convolution\n",
    "sf = SaveFeatures(model.features[-4])\n",
    "model.eval()\n",
    "\n",
    "if lab == 0:\n",
    "    # palsa_imgs+= 1\n",
    "    im = Variable(im).to(device)\n",
    "    outputs = model(im).to(device)\n",
    "    res = torch.argmax(outputs.data).cpu().detach().numpy()\n",
    "\n",
    "    # generate CAM\n",
    "    sf.remove()\n",
    "    arr = sf.features.cpu().detach().squeeze(0).squeeze(0).numpy()\n",
    "    print(arr, arr.shape)\n",
    "    # arr1 = arr[0]\n",
    "    # ans_palsa = np.dot(np.rollaxis(arr1,0,3), [0])\n",
    "\n",
    "    plt.imshow(arr, cmap='jet')\n",
    "    plt.show()\n",
    "\n",
    "    # CAM = resize(arr, (im_size*2,im_size*2))\n",
    "    \n",
    "    # # Plot image with CAM\n",
    "    # cpu_img = im.squeeze().cpu().detach().permute(1,2,0).long().numpy()\n",
    "\n",
    "    # fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,7))\n",
    "\n",
    "    # ax1.imshow(cpu_img)\n",
    "    # ax1.set_xticks([])\n",
    "    # ax1.set_yticks([])\n",
    "    # ax1.set_title('original image')\n",
    "\n",
    "    # ax2.imshow(cpu_img)\n",
    "    # ax2.imshow(CAM, alpha=.4, cmap='jet')\n",
    "    # ax2.set_xticks([])\n",
    "    # ax2.set_yticks([])\n",
    "    # ax2.set_title('image with CAM')\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    # wandb.log({'generated_CAM': fig})\n",
    "\n",
    "# if palsa_imgs == 10:\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGGING FORGOTTEN CAMS FROM SAVED MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load model again: \n",
    "\n",
    "run = wandb.init(project= 'VGG_CAMs', id= 'v6ax9crk', resume = 'must')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "artifact = run.use_artifact('nadjaflechner/VGG_CAMs/model:v9', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "state_dict = torch.load(f\"{artifact_dir}/model.pth\")\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_only_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
