{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class TestSet(Dataset):\n",
    "    def __init__(self, depth_layer, gt_dir, normalize):\n",
    "        self.RGB_dir = os.path.join(gt_dir, 'rgb')\n",
    "        self.hs_dir = os.path.join(gt_dir, 'hs')\n",
    "        self.dem_dir = os.path.join(gt_dir, 'dem')\n",
    "        self.groundtruth_dir = os.path.join(gt_dir, 'groundtruth_mask')\n",
    "        self.depth_dir = self.hs_dir if depth_layer == \"hs\" else self.dem_dir\n",
    "        self.labels_path = os.path.join(gt_dir, 'new_palsa_labels.csv')\n",
    "        self.im_size = 200\n",
    "        self.normalize = normalize\n",
    "\n",
    "        # configure labels file.\n",
    "        # only use samples where MS-Backe difference is <10%\n",
    "        unfiltered_labels_df = pd.read_csv(self.labels_path, index_col=0)\n",
    "        self.labels_df = unfiltered_labels_df.loc[\n",
    "            (unfiltered_labels_df['difference']<10)]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.labels_df.index[idx]\n",
    "        RGB_img_path = os.path.join(self.RGB_dir, f\"{img_name}.tif\")\n",
    "        hs_img_path = os.path.join(self.depth_dir, f\"{img_name}.tif\")\n",
    "\n",
    "        with rasterio.open(RGB_img_path) as RGB_src:\n",
    "            # Read the image data\n",
    "            RGB_img = RGB_src.read()\n",
    "\n",
    "        with rasterio.open(hs_img_path) as hs_src:\n",
    "            # Read the image data\n",
    "            hs_img = hs_src.read()\n",
    "\n",
    "        # convert and upsample hs image\n",
    "        hs_image_array = np.array(hs_img)\n",
    "        hs_image_tensor = torch.from_numpy(hs_image_array)\n",
    "        hs_image_tensor = hs_image_tensor.float()\n",
    "        bilinear = nn.Upsample(size=self.im_size*2, mode='bilinear')\n",
    "        hs_upsampled_tensor = bilinear(hs_image_tensor.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "        # converting RGB to tensor\n",
    "        RGB_image_array = np.array(RGB_img)\n",
    "        RGB_image_tensor = torch.from_numpy(RGB_image_array)\n",
    "        RGB_image_tensor = RGB_image_tensor.float()\n",
    "\n",
    "        combined_tensor = torch.concatenate((RGB_image_tensor, hs_upsampled_tensor))\n",
    "\n",
    "        if self.normalize:\n",
    "            # use dataset wide calculated means and standard deviations\n",
    "            if str(self.depth_dir).endswith('hs'):\n",
    "                transforms.Normalize(mean=[74.90, 85.26, 80.06, 179.18],\n",
    "                                     std=[15.05, 13.88, 12.01, 10.65])\n",
    "                pass\n",
    "            if str(self.depth_dir).endswith('dem'):\n",
    "                transforms.Normalize(mean=[74.90, 85.26, 80.06,608.95],\n",
    "                                     std=[15.05, 13.88, 12.01, 2.30])\n",
    "                pass\n",
    "\n",
    "        label = self.labels_df.iloc[idx, 0]\n",
    "        binary_label = 1 if label > 0 else 0\n",
    "        perc_label = label/100\n",
    "\n",
    "        # grab ground truth mask\n",
    "        gt_img_path = os.path.join(self.groundtruth_dir, f\"{img_name}.tif\")\n",
    "        with rasterio.open(gt_img_path) as gt_src:\n",
    "            gt_mask = gt_src.read()\n",
    "\n",
    "        gt_image_array = np.array(gt_mask)\n",
    "        gt_image_tensor = torch.from_numpy(gt_image_array)\n",
    "        gt_image_tensor = gt_image_tensor.float()\n",
    "        gt_upsampled_tensor = bilinear(gt_image_tensor.unsqueeze(0)).squeeze(0)  # OUTPUT is np array (1,200,200)\n",
    "\n",
    "        return combined_tensor, binary_label, perc_label, gt_upsampled_tensor, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# Imports #\n",
    "############\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "testset_dir = '/Users/nadja/Documents/UU/Thesis/Data/FINALFINAL_200m_groundtruths'\n",
    "depth_layer = 'hs'\n",
    "normalize = True\n",
    "\n",
    "test_set = TestSet(depth_layer, testset_dir, normalize)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=True, num_workers=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, lab, perc_label, gt_mask, img_name = next(iter(test_loader))\n",
    "if lab != 0: \n",
    "\n",
    "    print(img_name)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,6))\n",
    "\n",
    "    ax1.imshow(cpu_img[:,:,:3])\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_title('original image')\n",
    "\n",
    "    cpu_img = im.squeeze().cpu().detach().permute(1,2,0).long().numpy()\n",
    "\n",
    "    ax2.imshow(gt.squeeze(0).permute(1,2,0).long().numpy(), cmap=cmap, norm=norm)\n",
    "    ax2.set_xticks([])\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_title('Ground Truth')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "palsa_env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
