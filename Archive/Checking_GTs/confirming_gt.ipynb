{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadja/miniconda3/envs/torchvision/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/nadja/miniconda3/envs/torchvision/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <E03EDA44-89AE-3115-9796-62BA9E0E2EDE> /Users/nadja/miniconda3/envs/torchvision/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <2C8BF30B-D1BA-315D-BF33-9DF6F3757AB3> /Users/nadja/miniconda3/envs/torchvision/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# Imports #\n",
    "############\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from gt_dataset import TestSet\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "testset_dir = '/Users/nadja/Documents/UU/Thesis/Data/FINALFINAL_200m_groundtruths'\n",
    "depth_layer = 'hs'\n",
    "normalize = True\n",
    "\n",
    "test_set = TestSet(depth_layer, testset_dir, normalize)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for RGB_img, hs_img, perc_label, gt_mask, img_name in test_loader:\n",
    "\n",
    "    counter+=1\n",
    "    print(counter)\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (14,6))\n",
    "\n",
    "    ax1.imshow(np.transpose(np.squeeze(RGB_img), (1,2,0)))\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_title('Original Image')\n",
    "\n",
    "    ax2.imshow(np.squeeze(hs_img))\n",
    "    ax2.set_xticks([])\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_title('Hillshade')\n",
    "\n",
    "    ax3.imshow(np.squeeze(gt_mask))\n",
    "    ax3.set_xticks([])\n",
    "    ax3.set_yticks([])\n",
    "    ax3.set_title('Ground Truth')\n",
    "\n",
    "    fig.suptitle(f\"{str(img_name)[2:-3]} \\n \\n Backe's estimated palsa = {perc_label.item()*100} %\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filepath = f\"/Users/nadja/Documents/UU/Thesis/Data/Check_GTs/{str(img_name)[2:-3]}\"\n",
    "    plt.savefig(filepath)\n",
    "    # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "palsa_env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
