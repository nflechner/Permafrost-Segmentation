{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying missing SNIC pseudomasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TIF files without corresponding JPGs: 577\n",
      "Missing JPG files: ['763_72_5025_2018_negcrop_2.tif', '751_65_5050_2015_negcrop_7.tif', '758_66_5075_2010_crop_133.tif', '760_73_7500_2018_negcrop_11.tif', '761_75_7500_2015_negcrop_23.tif', '759_72_2575_2013_negcrop_13.tif', '760_71_7550_2018_crop_104.tif', '759_76_7575_2013_negcrop_1.tif', '761_73_0050_2018_crop_101.tif', '759_71_7550_2013_negcrop_1.tif', '758_73_0075_2013_crop_135.tif', '758_70_5075_2013_crop_2.tif', '761_72_2550_2018_crop_13.tif', '758_70_0050_2013_crop_105.tif', '754_68_5050_2015_crop_48.tif', '761_74_2500_2018_crop_123.tif', '749_61_0000_2019_crop_62.tif', '748_62_0025_2019_negcrop_9.tif', '761_73_5025_2018_crop_143.tif', '765_72_5025_2016_crop_40.tif', '765_73_5000_2016_crop_38.tif', '763_72_5050_2018_crop_57.tif', '757_72_7525_2013_negcrop_17.tif', '763_75_7525_2015_negcrop_7.tif', '761_71_0025_2018_crop_27.tif', '760_74_7500_2018_negcrop_42.tif', '756_69_7575_2014_crop_21.tif', '762_72_0075_2018_crop_31.tif', '763_71_7550_2018_negcrop_16.tif', '758_74_2500_2013_negcrop_3.tif', '756_67_0000_2016_negcrop_0.tif', '753_68_2525_2014_negcrop_12.tif', '761_73_0025_2018_crop_34.tif', '764_75_2500_2015_crop_10.tif', '761_73_0050_2018_negcrop_9.tif', '746_65_5075_2014_crop_38.tif', '758_73_2550_2013_crop_85.tif', '761_73_0075_2018_crop_123.tif', '764_74_7500_2018_negcrop_37.tif', '759_73_7525_2013_negcrop_14.tif', '760_71_2575_2018_crop_37.tif', '759_71_7550_2013_crop_112.tif', '765_74_2525_2016_negcrop_6.tif', '764_74_2575_2018_negcrop_28.tif', '756_70_5000_2010_negcrop_4.tif', '758_73_7500_2013_negcrop_37.tif', '757_67_2500_2010_crop_74.tif', '763_75_7525_2015_negcrop_5.tif', '758_74_2575_2013_crop_71.tif', '761_72_0075_2018_negcrop_6.tif', '759_68_0075_2014_crop_54.tif', '759_73_7500_2013_crop_112.tif', '760_74_5025_2018_crop_98.tif', '757_72_7550_2013_crop_51.tif', '748_62_2500_2019_crop_128.tif', '758_73_7500_2013_negcrop_22.tif', '748_62_2525_2019_negcrop_14.tif', '762_74_0000_2018_negcrop_2.tif', '763_72_5075_2018_crop_87.tif', '756_67_0000_2016_negcrop_3.tif', '756_65_5075_2016_crop_29.tif', '760_74_7500_2018_negcrop_5.tif', '764_71_2550_2018_crop_26.tif', '763_71_7550_2018_negcrop_7.tif', '759_73_0075_2013_negcrop_22.tif', '755_68_5025_2016_negcrop_7.tif', '754_67_7550_2015_negcrop_24.tif', '755_67_5025_2016_negcrop_2.tif', '751_66_7525_2015_crop_14.tif', '758_71_0000_2013_crop_32.tif', '759_72_5025_2013_negcrop_0.tif', '764_74_5075_2018_negcrop_33.tif', '763_72_5075_2018_negcrop_42.tif', '756_69_2575_2014_negcrop_2.tif', '763_72_0050_2018_crop_117.tif', '762_73_5075_2018_negcrop_9.tif', '763_72_5075_2018_crop_54.tif', '759_73_0050_2013_negcrop_0.tif', '760_74_7500_2018_crop_13.tif', '758_72_0075_2013_crop_66.tif', '765_74_2525_2016_negcrop_3.tif', '762_74_5025_2018_crop_40.tif', '759_76_7525_2013_crop_12.tif', '760_73_0000_2018_negcrop_21.tif', '757_67_2500_2010_negcrop_11.tif', '761_72_2575_2018_negcrop_18.tif', '747_66_0025_2014_crop_26.tif', '752_69_2500_2015_crop_61.tif', '745_64_7575_2016_crop_110.tif', '760_73_7525_2018_crop_122.tif', '763_75_7525_2015_negcrop_1.tif', '760_73_7500_2018_crop_34.tif', '763_73_5025_2018_crop_17.tif', '765_72_5075_2016_crop_93.tif', '761_72_5050_2018_crop_98.tif', '762_73_2525_2018_crop_14.tif', '760_74_7500_2018_crop_12.tif', '758_70_5000_2013_negcrop_37.tif', '762_73_5075_2018_negcrop_8.tif', '764_75_2500_2015_negcrop_46.tif', '763_71_5050_2018_negcrop_4.tif', '746_57_5000_2015_crop_56.tif', '756_67_0000_2016_negcrop_6.tif', '761_73_2550_2018_crop_55.tif', '746_56_2575_2015_crop_89.tif', '753_67_7550_2015_crop_73.tif', '761_73_7500_2018_crop_124.tif', '754_67_7550_2015_negcrop_33.tif', '755_68_5025_2016_negcrop_0.tif', '746_66_7500_2014_negcrop_18.tif', '761_74_7525_2018_crop_65.tif', '747_65_0050_2014_negcrop_4.tif', '751_65_5075_2015_negcrop_13.tif', '764_74_5075_2018_negcrop_18.tif', '759_72_5025_2013_negcrop_3.tif', '761_75_2525_2015_crop_62.tif', '762_77_5000_2015_crop_40.tif', '761_73_0050_2018_crop_104.tif', '758_73_2525_2013_crop_139.tif', '759_76_5000_2013_crop_122.tif', '760_74_7500_2018_crop_10.tif', '760_71_2575_2018_negcrop_14.tif', '758_73_2500_2013_crop_130.tif', '758_72_0075_2013_crop_65.tif', '759_72_2550_2013_negcrop_41.tif', '758_73_7500_2013_negcrop_19.tif', '760_73_7500_2018_crop_22.tif', '762_73_0000_2018_crop_72.tif', '760_74_5000_2018_negcrop_11.tif', '765_74_2500_2016_crop_41.tif', '757_70_5050_2013_crop_19.tif', '765_73_0075_2016_crop_14.tif', '761_72_0075_2018_negcrop_1.tif', '760_72_2550_2018_negcrop_3.tif', '758_74_5000_2013_negcrop_9.tif', '752_66_0075_2015_negcrop_10.tif', '757_67_2500_2010_crop_98.tif', '761_73_2500_2018_negcrop_28.tif', '759_76_7525_2013_negcrop_3.tif', '760_73_7575_2018_crop_31.tif', '761_76_2500_2015_negcrop_4.tif', '759_68_0050_2014_negcrop_11.tif', '759_68_0050_2014_crop_42.tif', '764_74_7500_2018_crop_10.tif', '752_68_2575_2015_negcrop_9.tif', '760_74_7500_2018_negcrop_3.tif', '759_80_7525_2013_crop_124.tif', '762_72_7500_2018_negcrop_4.tif', '764_73_2500_2018_negcrop_2.tif', '748_62_5000_2019_crop_42.tif', '763_73_0000_2018_negcrop_0.tif', '758_66_5025_2010_negcrop_1.tif', '752_66_0075_2015_crop_91.tif', '758_66_5050_2010_negcrop_1.tif', '749_66_2500_2014_crop_125.tif', '749_61_0000_2019_crop_102.tif', '761_75_0000_2015_crop_74.tif', '753_67_2550_2014_crop_55.tif', '761_75_0000_2015_negcrop_3.tif', '762_74_0075_2018_negcrop_4.tif', '758_70_2500_2013_crop_77.tif', '759_73_0000_2013_negcrop_29.tif', '758_73_7500_2013_negcrop_9.tif', '750_65_7575_2015_negcrop_42.tif', '757_66_2575_2010_negcrop_2.tif', '761_73_2525_2018_negcrop_30.tif', '760_72_0025_2018_negcrop_5.tif', '758_73_2500_2013_negcrop_0.tif', '750_65_7550_2015_negcrop_15.tif', '761_71_5000_2018_crop_46.tif', '763_73_0050_2018_crop_98.tif', '762_72_7525_2018_negcrop_2.tif', '761_75_5050_2015_negcrop_16.tif', '765_73_0075_2016_negcrop_7.tif', '764_71_0050_2018_crop_26.tif', '756_70_2500_2010_crop_31.tif', '760_72_0050_2018_crop_135.tif', '760_75_0075_2015_crop_17.tif', '760_71_2550_2018_negcrop_3.tif', '750_65_5050_2015_negcrop_0.tif', '759_73_0000_2013_negcrop_14.tif', '750_65_7575_2015_negcrop_43.tif', '753_65_0075_2015_crop_71.tif', '759_76_7500_2013_negcrop_4.tif', '760_73_7575_2018_negcrop_19.tif', '761_73_0025_2018_crop_120.tif', '763_72_5075_2018_negcrop_26.tif', '758_73_0050_2013_negcrop_1.tif', '759_76_5000_2013_negcrop_10.tif', '758_66_5050_2010_negcrop_0.tif', '763_73_5000_2018_negcrop_14.tif', '765_74_2500_2016_negcrop_47.tif', '759_73_0075_2013_crop_25.tif', '761_73_5000_2018_crop_4.tif', '761_71_0050_2018_negcrop_11.tif', '764_71_2550_2018_crop_50.tif', '758_70_2525_2013_negcrop_4.tif', '763_72_7500_2018_negcrop_19.tif', '760_71_7550_2018_negcrop_8.tif', '760_74_5000_2018_crop_28.tif', '760_73_5050_2018_negcrop_6.tif', '764_75_2500_2015_negcrop_35.tif', '750_65_7550_2015_negcrop_16.tif', '757_70_5050_2013_negcrop_1.tif', '762_77_7500_2015_crop_50.tif', '748_61_7575_2019_negcrop_6.tif', '759_73_7500_2013_crop_50.tif', '762_77_7500_2015_crop_9.tif', '762_72_0075_2018_negcrop_24.tif', '762_72_0075_2018_negcrop_18.tif', '753_67_2575_2014_negcrop_6.tif', '750_65_7550_2015_negcrop_5.tif', '758_70_5075_2013_crop_28.tif', '759_76_5075_2013_crop_105.tif', '760_72_5050_2018_crop_71.tif', '761_73_0000_2018_crop_79.tif', '765_73_0075_2016_negcrop_29.tif', '750_65_5050_2015_negcrop_3.tif', '765_73_0075_2016_negcrop_15.tif', '748_62_5000_2019_negcrop_0.tif', '762_77_5000_2015_crop_18.tif', '764_74_7500_2018_crop_130.tif', '760_72_2525_2018_negcrop_22.tif', '762_72_2525_2018_crop_141.tif', '758_73_2550_2013_negcrop_4.tif', '758_69_7525_2014_crop_77.tif', '755_67_7525_2016_crop_5.tif', '761_72_2550_2018_negcrop_14.tif', '760_72_5075_2018_crop_74.tif', '750_65_7575_2015_crop_132.tif', '758_71_0000_2013_crop_69.tif', '761_76_0000_2015_crop_104.tif', '752_66_0075_2015_crop_87.tif', '759_72_7550_2013_negcrop_6.tif', '759_72_7550_2013_negcrop_2.tif', '760_71_7550_2018_crop_85.tif', '756_68_2550_2016_crop_5.tif', '758_73_2500_2013_crop_23.tif', '753_67_2575_2014_crop_100.tif', '761_74_7525_2018_crop_39.tif', '751_69_7500_2015_crop_120.tif', '764_74_5075_2018_negcrop_50.tif', '763_72_7500_2018_crop_78.tif', '764_75_2500_2015_crop_109.tif', '764_73_0025_2018_negcrop_4.tif', '760_73_5025_2018_crop_32.tif', '764_75_0000_2015_negcrop_9.tif', '747_65_0075_2014_negcrop_4.tif', '763_71_7575_2018_negcrop_0.tif', '749_68_0025_2014_negcrop_3.tif', '764_75_0025_2015_negcrop_19.tif', '765_72_2575_2016_crop_3.tif', '759_73_7500_2013_crop_40.tif', '761_72_2500_2018_crop_137.tif', '760_74_7550_2018_crop_72.tif', '735_54_5050_2013_crop_45.tif', '764_74_7525_2018_negcrop_13.tif', '761_71_5025_2018_negcrop_8.tif', '763_72_2500_2018_crop_80.tif', '761_73_0075_2018_negcrop_49.tif', '756_65_7525_2016_negcrop_3.tif', '758_73_2550_2013_negcrop_1.tif', '747_61_2525_2014_crop_134.tif', '754_66_0050_2015_negcrop_0.tif', '764_74_7575_2018_negcrop_12.tif', '758_70_2575_2013_negcrop_20.tif', '734_52_2575_2015_crop_52.tif', '763_72_2525_2018_crop_85.tif', '761_72_0050_2018_negcrop_2.tif', '761_71_0050_2018_negcrop_17.tif', '750_65_7575_2015_crop_55.tif', '759_72_7550_2013_negcrop_1.tif', '761_72_0025_2018_negcrop_12.tif', '758_70_2575_2013_crop_115.tif', '764_74_7500_2018_crop_123.tif', '761_73_0050_2018_negcrop_20.tif', '761_71_0025_2018_negcrop_3.tif', '760_71_7500_2018_negcrop_8.tif', '758_70_0000_2013_crop_129.tif', '760_80_2525_2013_crop_126.tif', '762_74_0050_2018_crop_34.tif', '753_65_0075_2015_negcrop_1.tif', '764_71_0050_2018_negcrop_14.tif', '760_74_7525_2018_negcrop_0.tif', '756_70_7575_2010_negcrop_1.tif', '751_66_5025_2015_negcrop_23.tif', '761_72_5050_2018_negcrop_18.tif', '760_73_0000_2018_crop_27.tif', '761_72_5050_2018_crop_128.tif', '760_72_0050_2018_negcrop_19.tif', '761_71_5050_2018_crop_105.tif', '763_71_5025_2018_negcrop_3.tif', '756_65_7525_2016_negcrop_0.tif', '759_76_7500_2013_negcrop_1.tif', '759_72_0000_2013_crop_71.tif', '761_76_0000_2015_crop_102.tif', '765_72_5075_2016_negcrop_16.tif', '751_66_2550_2015_crop_49.tif', '760_74_7550_2018_negcrop_25.tif', '748_62_5000_2019_crop_21.tif', '759_76_5000_2013_negcrop_7.tif', '761_74_7550_2018_crop_116.tif', '764_75_0000_2015_negcrop_40.tif', '758_70_2550_2013_crop_69.tif', '755_68_5025_2016_crop_27.tif', '761_72_2550_2018_negcrop_23.tif', '761_74_2500_2018_negcrop_1.tif', '747_62_5025_2019_negcrop_7.tif', '749_66_2500_2014_negcrop_5.tif', '751_66_7500_2015_negcrop_12.tif', '761_74_0000_2018_negcrop_43.tif', '763_75_0075_2015_crop_116.tif', '761_72_5050_2018_crop_125.tif', '761_72_0075_2018_crop_35.tif', '761_73_0000_2018_negcrop_39.tif', '759_73_0050_2013_negcrop_21.tif', '761_72_2525_2018_crop_125.tif', '747_64_2575_2019_negcrop_0.tif', '760_77_0000_2015_crop_23.tif', '761_71_0025_2018_crop_59.tif', '763_71_2550_2018_crop_35.tif', '759_68_0075_2014_negcrop_15.tif', '761_71_5000_2018_crop_66.tif', '759_68_0075_2014_negcrop_29.tif', '754_67_7525_2015_negcrop_23.tif', '750_66_0075_2015_crop_86.tif', '733_52_2500_2015_crop_35.tif', '761_73_0075_2018_crop_49.tif', '761_71_5075_2018_negcrop_1.tif', '760_72_5075_2018_crop_108.tif', '761_72_5000_2018_negcrop_0.tif', '759_72_2525_2013_crop_31.tif', '762_74_7525_2018_negcrop_5.tif', '763_73_5000_2018_crop_97.tif', '761_71_0050_2018_crop_49.tif', '761_74_0000_2018_negcrop_4.tif', '764_74_7500_2018_negcrop_7.tif', '760_74_5025_2018_negcrop_16.tif', '749_66_2500_2014_negcrop_6.tif', '760_73_5000_2018_negcrop_13.tif', '759_72_2575_2013_crop_30.tif', '761_72_7500_2018_negcrop_4.tif', '761_76_0000_2015_negcrop_13.tif', '753_67_2525_2014_crop_71.tif', '758_72_7575_2013_crop_85.tif', '761_73_0000_2018_crop_59.tif', '758_73_2550_2013_negcrop_29.tif', '764_75_2500_2015_negcrop_3.tif', '750_68_0000_2015_crop_110.tif', '761_72_5050_2018_negcrop_16.tif', '757_72_5050_2013_negcrop_0.tif', '764_74_7525_2018_crop_50.tif', '758_72_0025_2013_crop_2.tif', '759_69_0025_2014_negcrop_0.tif', '761_71_5025_2018_negcrop_13.tif', '760_72_0075_2018_crop_47.tif', '757_66_2575_2010_crop_70.tif', '761_75_7500_2015_negcrop_7.tif', '751_65_5075_2015_crop_89.tif', '759_72_0025_2013_negcrop_11.tif', '761_75_5000_2015_negcrop_1.tif', '759_73_7500_2013_negcrop_28.tif', '759_73_0000_2013_negcrop_22.tif', '761_70_2575_2018_crop_132.tif', '761_72_5025_2018_crop_8.tif', '763_74_7500_2018_negcrop_2.tif', '758_73_5050_2013_negcrop_36.tif', '753_67_7575_2015_negcrop_8.tif', '746_65_7550_2014_negcrop_3.tif', '763_74_5000_2018_negcrop_0.tif', '761_71_0050_2018_crop_64.tif', '734_52_2575_2015_crop_99.tif', '761_73_0025_2018_negcrop_1.tif', '763_75_5075_2015_crop_70.tif', '760_74_5000_2018_crop_18.tif', '760_71_7500_2018_crop_136.tif', '764_74_7500_2018_crop_44.tif', '761_74_0025_2018_negcrop_12.tif', '761_73_2575_2018_crop_127.tif', '750_65_7550_2015_negcrop_8.tif', '750_66_0075_2015_negcrop_0.tif', '760_74_5000_2018_negcrop_50.tif', '756_67_0000_2016_crop_40.tif', '761_73_0000_2018_negcrop_17.tif', '760_72_7575_2018_negcrop_2.tif', '762_72_2575_2018_negcrop_3.tif', '761_74_0000_2018_crop_47.tif', '764_71_2525_2018_negcrop_2.tif', '765_73_0075_2016_negcrop_19.tif', '765_72_2550_2016_negcrop_0.tif', '751_66_7500_2015_negcrop_15.tif', '763_73_7525_2018_crop_132.tif', '764_74_2575_2018_crop_45.tif', '746_65_5050_2014_negcrop_0.tif', '750_66_2525_2015_negcrop_1.tif', '760_74_7525_2018_negcrop_45.tif', '761_71_0000_2018_crop_72.tif', '762_73_5075_2018_negcrop_11.tif', '761_73_5000_2018_crop_9.tif', '760_71_0075_2018_crop_108.tif', '761_71_5025_2018_crop_98.tif', '760_72_2525_2018_crop_104.tif', '752_65_7550_2015_negcrop_3.tif', '762_73_5025_2018_crop_142.tif', '761_73_2525_2018_negcrop_14.tif', '758_70_5000_2013_crop_34.tif', '747_62_5025_2019_crop_69.tif', '758_70_5025_2013_negcrop_4.tif', '764_74_5050_2018_negcrop_1.tif', '761_73_2575_2018_crop_10.tif', '754_67_7550_2015_crop_88.tif', '758_73_2525_2013_crop_10.tif', '758_73_7550_2013_negcrop_3.tif', '759_72_2550_2013_negcrop_17.tif', '761_72_0075_2018_negcrop_26.tif', '758_71_2500_2013_negcrop_4.tif', '759_73_0000_2013_crop_10.tif', '751_66_5025_2015_crop_101.tif', '761_77_5050_2013_negcrop_2.tif', '759_77_5025_2013_negcrop_0.tif', '761_73_0000_2018_negcrop_15.tif', '758_72_2550_2013_crop_42.tif', '761_77_5050_2013_negcrop_3.tif', '761_73_5025_2018_crop_49.tif', '761_72_2575_2018_negcrop_58.tif', '751_66_5025_2015_crop_114.tif', '761_79_2575_2013_negcrop_2.tif', '765_74_2500_2016_crop_7.tif', '750_65_7550_2015_negcrop_24.tif', '758_71_0000_2013_negcrop_3.tif', '747_62_5025_2019_crop_68.tif', '753_68_2525_2014_crop_90.tif', '753_67_2550_2014_crop_64.tif', '760_73_5050_2018_negcrop_8.tif', '755_67_5025_2016_crop_139.tif', '748_62_2500_2019_negcrop_0.tif', '761_72_0050_2018_crop_134.tif', '750_65_7575_2015_crop_115.tif', '763_73_5000_2018_crop_47.tif', '760_72_2550_2018_negcrop_53.tif', '746_65_5075_2014_crop_26.tif', '760_72_2525_2018_crop_93.tif', '746_57_5025_2015_crop_107.tif', '761_72_0050_2018_crop_84.tif', '759_76_5075_2013_negcrop_11.tif', '759_71_0050_2013_crop_99.tif', '761_74_0000_2018_negcrop_34.tif', '763_74_5000_2018_negcrop_11.tif', '760_71_7575_2018_negcrop_0.tif', '761_73_2500_2018_negcrop_3.tif', '765_72_2575_2016_negcrop_5.tif', '759_72_0025_2013_negcrop_6.tif', '759_73_0000_2013_crop_8.tif', '763_71_5050_2018_crop_24.tif', '759_76_5025_2013_crop_133.tif', '760_71_5050_2018_crop_8.tif', '748_62_2525_2019_negcrop_6.tif', '758_73_7500_2013_crop_49.tif', '760_72_5050_2018_negcrop_17.tif', '761_73_7525_2018_negcrop_12.tif', '760_72_2500_2018_crop_40.tif', '764_75_0000_2015_crop_91.tif', '764_74_7525_2018_negcrop_7.tif', '758_72_0025_2013_crop_94.tif', '760_71_2575_2018_negcrop_25.tif', '761_73_0000_2018_crop_38.tif', '746_57_5075_2015_crop_88.tif', '758_66_7550_2010_crop_42.tif', '746_58_0000_2015_negcrop_2.tif', '760_73_5025_2018_negcrop_9.tif', '755_68_5025_2016_crop_45.tif', '759_72_2550_2013_crop_109.tif', '761_73_2550_2018_negcrop_25.tif', '759_72_7525_2013_negcrop_8.tif', '762_77_7500_2015_negcrop_10.tif', '761_71_7500_2018_negcrop_1.tif', '749_68_2550_2014_crop_128.tif', '757_72_7525_2013_crop_63.tif', '761_71_5000_2018_negcrop_33.tif', '763_73_2500_2018_crop_93.tif', '760_74_7525_2018_crop_32.tif', '761_73_2550_2018_crop_64.tif', '754_68_5075_2015_crop_53.tif', '765_72_5075_2016_negcrop_9.tif', '759_72_7550_2013_negcrop_13.tif', '763_72_0050_2018_crop_67.tif', '761_73_0050_2018_negcrop_0.tif', '756_70_5000_2010_negcrop_14.tif', '761_72_0050_2018_crop_50.tif', '746_58_0000_2015_negcrop_0.tif', '755_67_5025_2016_negcrop_17.tif', '761_71_5000_2018_negcrop_7.tif', '761_73_0075_2018_crop_116.tif', '758_73_2525_2013_negcrop_8.tif', '758_73_2550_2013_crop_73.tif', '751_66_7500_2015_crop_21.tif', '760_73_5025_2018_negcrop_33.tif', '759_73_0000_2013_crop_61.tif', '751_65_0050_2015_negcrop_4.tif', '759_72_0025_2013_crop_137.tif', '764_73_0025_2018_crop_67.tif', '747_65_0075_2014_crop_46.tif', '758_73_0050_2013_negcrop_20.tif', '762_74_5000_2018_negcrop_2.tif', '754_67_7550_2015_crop_13.tif', '764_74_5025_2018_negcrop_2.tif', '764_74_0000_2018_crop_44.tif', '758_70_5000_2013_crop_93.tif', '758_73_0050_2013_crop_137.tif', '761_72_0050_2018_crop_51.tif', '759_72_5025_2013_negcrop_13.tif', '765_73_2575_2016_crop_91.tif', '759_71_5075_2013_crop_73.tif', '761_73_2550_2018_negcrop_32.tif', '746_66_7500_2014_negcrop_16.tif', '761_72_0000_2018_crop_56.tif', '752_68_0075_2015_negcrop_4.tif', '759_76_2575_2013_crop_4.tif', '763_73_5050_2018_negcrop_4.tif', '760_71_0075_2018_negcrop_9.tif', '758_70_5000_2013_crop_40.tif', '761_73_2500_2018_negcrop_37.tif', '749_68_2550_2014_negcrop_9.tif', '763_71_2550_2018_crop_45.tif', '764_74_7525_2018_negcrop_44.tif', '760_74_2500_2018_crop_2.tif', '764_74_5025_2018_crop_114.tif', '762_74_5025_2018_crop_61.tif', '761_75_2525_2015_negcrop_8.tif', '763_72_5050_2018_crop_70.tif', '760_71_2550_2018_crop_16.tif', '756_69_7550_2014_crop_117.tif', '747_65_0075_2014_crop_57.tif', '746_66_7500_2014_negcrop_5.tif', '762_78_0000_2013_negcrop_0.tif', '756_65_7525_2016_crop_53.tif', '757_72_7525_2013_negcrop_6.tif', '757_72_7575_2013_negcrop_24.tif', '758_73_0050_2013_crop_132.tif', '764_72_0050_2018_crop_127.tif', '752_67_2575_2015_negcrop_2.tif', '752_68_2575_2015_negcrop_3.tif', '760_72_7550_2018_negcrop_0.tif', '758_73_5075_2013_negcrop_5.tif', '758_70_0025_2013_crop_95.tif', '753_69_5050_2014_crop_13.tif', '758_70_5050_2013_negcrop_15.tif', '747_62_7550_2019_negcrop_0.tif', '759_80_7525_2013_crop_110.tif', '760_72_2550_2018_negcrop_25.tif', '751_65_0050_2015_negcrop_10.tif', '764_74_5075_2018_negcrop_3.tif', '758_70_0050_2013_negcrop_9.tif', '750_65_7575_2015_negcrop_39.tif', '746_57_5050_2015_negcrop_8.tif', '762_74_5000_2018_negcrop_5.tif', '758_73_5025_2013_crop_14.tif', '747_66_0025_2014_crop_38.tif', '761_73_0000_2018_negcrop_0.tif', '757_72_7525_2013_negcrop_27.tif', '761_72_0075_2018_crop_85.tif', '758_74_5000_2013_negcrop_0.tif', '760_74_5000_2018_negcrop_19.tif', '755_69_7575_2014_crop_95.tif', '745_65_5000_2016_negcrop_0.tif', '751_66_7500_2015_crop_32.tif', '764_71_2550_2018_negcrop_14.tif', '748_62_2525_2019_crop_29.tif', '759_72_5000_2013_crop_35.tif', '763_74_5000_2018_negcrop_15.tif', '758_70_5000_2013_crop_56.tif', '750_66_5050_2015_crop_139.tif', '756_70_0000_2010_crop_16.tif', '759_76_7500_2013_crop_34.tif', '765_73_2575_2016_crop_40.tif', '757_72_7525_2013_crop_64.tif', '747_62_7550_2019_negcrop_1.tif']\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "tif_folder = \"/Volumes/USB/Orig_200m_TIFS/rgb\"\n",
    "jpg_folder = \"/Volumes/USB/Pseudomasks/orig_SNIC_pseudomasks/images\"\n",
    "\n",
    "orig_files = [file for file in os.listdir(tif_folder) if not file.endswith('_aug.tif') and not file.startswith('._')]\n",
    "thresholded_cams = [file for file in os.listdir(jpg_folder) if not file.startswith('._')]\n",
    "\n",
    "# List to store TIF files without corresponding JPG files\n",
    "missing_jpgs = []\n",
    "\n",
    "# Check for TIF files in the folder\n",
    "for tif_file in orig_files:\n",
    "    if tif_file.endswith('.tif'):\n",
    "        jpg_file = tif_file.replace('.tif', '.jpg')\n",
    "        if not os.path.exists(os.path.join(jpg_folder, jpg_file)):\n",
    "            missing_jpgs.append(tif_file)\n",
    "\n",
    "# Print the count and list of missing JPG files\n",
    "print(f\"Number of TIF files without corresponding JPGs: {len(missing_jpgs)}\")\n",
    "print(\"Missing JPG files:\", missing_jpgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palsa_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>760_73_5025_2018_crop_32</th>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760_73_5025_2018_negcrop_9</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760_73_5025_2018_negcrop_33</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752_65_7550_2015_negcrop_3</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765_73_5000_2016_crop_38</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             palsa_percentage\n",
       "760_73_5025_2018_crop_32                 2.25\n",
       "760_73_5025_2018_negcrop_9               0.00\n",
       "760_73_5025_2018_negcrop_33              0.00\n",
       "752_65_7550_2015_negcrop_3               0.00\n",
       "765_73_5000_2016_crop_38                 0.25"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "labels_file = \"/Volumes/USB/Orig_200m_TIFS/new_palsa_labels.csv\"\n",
    "all_files = pd.read_csv(labels_file, index_col=0)\n",
    "\n",
    "# Keep only the rows whose index name is in missing_jpgs (with the .tif extension)\n",
    "missing_jpgs = all_files.loc[all_files.index.isin([file.replace('.tif', '') for file in missing_jpgs])]\n",
    "missing_jpgs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "577"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_jpgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# Imports #\n",
    "############\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "from model.cnn_classifier import model_4D\n",
    "from model.pseudomask import Pseudomasks\n",
    "from utils.data_modules import ImageDataset, TestSet, filter_dataset\n",
    "\n",
    "##################\n",
    "## load configs ##\n",
    "##################\n",
    "\n",
    "rgb_dir = \"/Volumes/USB/Orig_200m_TIFS/rgb\"\n",
    "hs_dir = \"/Volumes/USB/Orig_200m_TIFS/hs\"\n",
    "\n",
    "# assign model\n",
    "artifact_path = \"nadjaflechner/VGG_CAMs/classification_model:v61\"\n",
    "batch_size = 20\n",
    "im_size = 200\n",
    "min_palsa_positive_samples = 0\n",
    "augment = False\n",
    "normalize = False\n",
    "depth_layer = 'hs'\n",
    "\n",
    "# assign pseudomasks configs\n",
    "cam_threshold_factor = 0.87\n",
    "overlap_threshold = 0.46\n",
    "snic_seeds = 100\n",
    "snic_compactness = 4\n",
    "finetune = False\n",
    "std_from_mean = 0\n",
    "\n",
    "# choose depth data based on configs\n",
    "depth_dir = hs_dir\n",
    "# Create the dataset and loaders for the entire dataset.\n",
    "dataset = ImageDataset(depth_dir, rgb_dir, missing_jpgs, im_size, normalize)\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "#############\n",
    "# Init model: \n",
    "\n",
    "api = wandb.Api()\n",
    "artifact = api.artifact(artifact_path, type='model')\n",
    "artifact_dir = artifact.download()\n",
    "state_dict = torch.load(f\"{artifact_dir}/model.pth\", map_location=torch.device('cpu'))\n",
    "model = model_4D()\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "#############################\n",
    "# generate all pseudolabels #\n",
    "#############################\n",
    "\n",
    "pseudomask_generator = Pseudomasks(\n",
    "    dataset, cam_threshold_factor, overlap_threshold,\n",
    "    snic_seeds, snic_compactness, finetuned = finetune, std_from_mean=0\n",
    "    )\n",
    "pseudomask_generator.model = model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_generated = os.listdir(\"/Volumes/USB/Pseudomasks/orig_SNIC_pseudomasks/newly_generated/images\")\n",
    "missing_jpgs = missing_jpgs[~missing_jpgs.index.isin([f[:-4] for f in files_generated if f.endswith('.jpg')])]\n",
    "\n",
    "dataset = ImageDataset(depth_dir, rgb_dir, missing_jpgs, im_size, normalize)\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "pseudomask_generator = Pseudomasks(\n",
    "    dataset, cam_threshold_factor, overlap_threshold,\n",
    "    snic_seeds, snic_compactness, finetuned = finetune, std_from_mean=0\n",
    "    )\n",
    "pseudomask_generator.model = model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "len(missing_jpgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           palsa_percentage\n",
      "764_74_7500_2018_crop_123              2.50\n",
      "759_76_5025_2013_crop_133              2.25\n",
      "760_77_0000_2015_crop_23               3.25\n"
     ]
    }
   ],
   "source": [
    "print(missing_jpgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "RasterioIOError",
     "evalue": "'/Volumes/USB/Orig_200m_TIFS/rgb/764_74_7500_2018_crop_123.tif' not recognized as a supported file format.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mrasterio/_base.pyx:261\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_shim.pyx:78\u001b[0m, in \u001b[0;36mrasterio._shim.open_dataset\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_err.pyx:216\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: '/Volumes/USB/Orig_200m_TIFS/rgb/764_74_7500_2018_crop_123.tif' not recognized as a supported file format.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# files_generated = os.listdir(\"/Volumes/USB/Pseudomasks/orig_SNIC_pseudomasks/newly_generated/images\")\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m im,binary_label,_,img_name \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;66;03m# if not f\"{img_name}.jpg\" in files_generated:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# output paths:\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         output_path_mask \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Volumes/USB/Pseudomasks/orig_SNIC_pseudomasks/newly_generated/masks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_name[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n",
      "File \u001b[0;32m~/miniconda3/envs/torchvision/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/torchvision/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/torchvision/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/torchvision/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/1. Project/Thesis/Permafrost-Segmentation/Current_Version/pseudomasks/utils/data_modules.py:71\u001b[0m, in \u001b[0;36mImageDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     68\u001b[0m RGB_img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRGB_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     69\u001b[0m hs_img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m rasterio\u001b[38;5;241m.\u001b[39mopen(RGB_img_path) \u001b[38;5;28;01mas\u001b[39;00m RGB_src:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Read the image data\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     RGB_img \u001b[38;5;241m=\u001b[39m RGB_src\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m rasterio\u001b[38;5;241m.\u001b[39mopen(hs_img_path) \u001b[38;5;28;01mas\u001b[39;00m hs_src:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# Read the image data\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torchvision/lib/python3.11/site-packages/rasterio/env.py:437\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    434\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/torchvision/lib/python3.11/site-packages/rasterio/__init__.py:220\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Create dataset instances and pass the given env, which will\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# be taken over by the dataset's context manager if it is not\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# None.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 220\u001b[0m     s \u001b[38;5;241m=\u001b[39m DatasetReader(path, driver\u001b[38;5;241m=\u001b[39mdriver, sharing\u001b[38;5;241m=\u001b[39msharing, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    222\u001b[0m     s \u001b[38;5;241m=\u001b[39m get_writer_for_path(path, driver\u001b[38;5;241m=\u001b[39mdriver)(\n\u001b[1;32m    223\u001b[0m         path, mode, driver\u001b[38;5;241m=\u001b[39mdriver, sharing\u001b[38;5;241m=\u001b[39msharing, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32mrasterio/_base.pyx:263\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRasterioIOError\u001b[0m: '/Volumes/USB/Orig_200m_TIFS/rgb/764_74_7500_2018_crop_123.tif' not recognized as a supported file format."
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "# files_generated = os.listdir(\"/Volumes/USB/Pseudomasks/orig_SNIC_pseudomasks/newly_generated/images\")\n",
    "for im,binary_label,_,img_name in loader:\n",
    "\n",
    "    try:\n",
    "        # if not f\"{img_name}.jpg\" in files_generated:\n",
    "\n",
    "        # output paths:\n",
    "        output_path_mask = os.path.join(\"/Volumes/USB/Pseudomasks/orig_SNIC_pseudomasks/newly_generated/masks\", f\"{img_name[0]}.png\") \n",
    "        output_path_jpg = os.path.join(\"/Volumes/USB/Pseudomasks/orig_SNIC_pseudomasks/newly_generated/images\", f\"{img_name[0]}.jpg\") \n",
    "\n",
    "        # Save RGB image\n",
    "        vutils.save_image((im[:,:3,:,:]/255).cpu(), output_path_jpg, normalize = False)\n",
    "\n",
    "        # Generate pseudomask \n",
    "        if binary_label == 0: \n",
    "            pseudomask = np.full((400, 400), False, dtype=bool)\n",
    "        else:\n",
    "            pseudomask = pseudomask_generator.generate_mask(im, None, save_plot=False)\n",
    "\n",
    "        # Save pseudomask\n",
    "        binary_pseudomask = np.squeeze(pseudomask.astype(np.uint8)) # convert bool to binary mask\n",
    "        pseudomask_img = Image.fromarray(binary_pseudomask) # convert to pil img\n",
    "        pseudomask_img.save(output_path_mask) # save as binary png\n",
    "\n",
    "        counter+= 1\n",
    "\n",
    "        if counter%10 ==0:\n",
    "            print(f\"{counter} images produced\")\n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate thresholded CAMs that were not generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset kernel before attempting this!|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "tif_folder = \"/Volumes/USB/Orig_200m_TIFS/rgb\"\n",
    "jpg_folder = \"/Volumes/USB/Pseudomasks/Thresholded_CAM/images\"\n",
    "\n",
    "orig_files = [file for file in os.listdir(tif_folder) if not file.endswith('_aug.tif') and not file.startswith('._')]\n",
    "thresholded_cams = [file for file in os.listdir(jpg_folder) if not file.startswith('._')]\n",
    "\n",
    "# List to store TIF files without corresponding JPG files\n",
    "missing_jpgs = []\n",
    "\n",
    "# Check for TIF files in the folder\n",
    "for tif_file in orig_files:\n",
    "    if tif_file.endswith('.tif'):\n",
    "        jpg_file = tif_file.replace('.tif', '.jpg')\n",
    "        if not os.path.exists(os.path.join(jpg_folder, jpg_file)):\n",
    "            missing_jpgs.append(tif_file)\n",
    "\n",
    "# Print the count and list of missing JPG files\n",
    "print(f\"Number of TIF files without corresponding JPGs: {len(missing_jpgs)}\")\n",
    "print(\"Missing JPG files:\", missing_jpgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "labels_file = \"/Volumes/USB/Orig_200m_TIFS/new_palsa_labels.csv\"\n",
    "all_files = pd.read_csv(labels_file, index_col=0)\n",
    "\n",
    "# Keep only the rows whose index name is in missing_jpgs (with the .tif extension)\n",
    "missing_jpgs = all_files.loc[all_files.index.isin([file.replace('.tif', '') for file in missing_jpgs])]\n",
    "missing_jpgs.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the df is the same length as number of missing files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missing_jpgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# Imports #\n",
    "############\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "from model.cnn_classifier import model_4D\n",
    "from model.pseudomask import Pseudomasks\n",
    "from utils.data_modules import ImageDataset, TestSet, filter_dataset\n",
    "\n",
    "##################\n",
    "## load configs ##\n",
    "##################\n",
    "\n",
    "rgb_dir = \"/Volumes/USB/Orig_200m_TIFS/rgb\"\n",
    "hs_dir = \"/Volumes/USB/Orig_200m_TIFS/hs\"\n",
    "\n",
    "# assign model\n",
    "artifact_path = \"nadjaflechner/VGG_CAMs/classification_model:v61\"\n",
    "batch_size = 20\n",
    "im_size = 200\n",
    "min_palsa_positive_samples = 0\n",
    "augment = False\n",
    "normalize = False\n",
    "depth_layer = 'hs'\n",
    "\n",
    "# assign pseudomasks configs\n",
    "cam_threshold_factor = 0.87\n",
    "overlap_threshold = 0.46\n",
    "snic_seeds = 100\n",
    "snic_compactness = 4\n",
    "finetune = False\n",
    "std_from_mean = 0\n",
    "\n",
    "# choose depth data based on configs\n",
    "depth_dir = hs_dir\n",
    "# Create the dataset and loaders for the entire dataset.\n",
    "dataset = ImageDataset(depth_dir, rgb_dir, missing_jpgs, im_size, normalize)\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "#############\n",
    "# Init model: \n",
    "\n",
    "api = wandb.Api()\n",
    "artifact = api.artifact(artifact_path, type='model')\n",
    "artifact_dir = artifact.download()\n",
    "state_dict = torch.load(f\"{artifact_dir}/model.pth\", map_location=torch.device('cpu'))\n",
    "model = model_4D()\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "#############################\n",
    "# generate all pseudolabels #\n",
    "#############################\n",
    "\n",
    "pseudomask_generator = Pseudomasks(\n",
    "    dataset, cam_threshold_factor, overlap_threshold,\n",
    "    snic_seeds, snic_compactness, finetuned = finetune, std_from_mean=0\n",
    "    )\n",
    "pseudomask_generator.model = model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    try: \n",
    "        counter = 0\n",
    "        files_generated = os.listdir(\"/Volumes/USB/Pseudomasks/Thresholded_CAM/newly_generated/images\")\n",
    "        for im,binary_label,_,img_name in loader:\n",
    "\n",
    "            if not f\"{img_name}.jpg\" in files_generated:\n",
    "\n",
    "                # output paths:\n",
    "                output_path_mask = os.path.join(\"/Volumes/USB/Pseudomasks/Thresholded_CAM/newly_generated/masks\", f\"{img_name[0]}.png\") \n",
    "                output_path_jpg = os.path.join(\"/Volumes/USB/Pseudomasks/Thresholded_CAM/newly_generated/images\", f\"{img_name[0]}.jpg\") \n",
    "\n",
    "                # Save RGB image\n",
    "                vutils.save_image((im[:,:3,:,:]/255).cpu(), output_path_jpg, normalize = False)\n",
    "\n",
    "                # Generate pseudomask \n",
    "                if binary_label == 0: \n",
    "                    pseudomask = np.full((400, 400), False, dtype=bool)\n",
    "                else:\n",
    "                    pseudomask = pseudomask_generator.generate_thresholded_CAM(im, None, save_plot=False)\n",
    "\n",
    "                # Save pseudomask\n",
    "                binary_pseudomask = np.squeeze(pseudomask.astype(np.uint8)) # convert bool to binary mask\n",
    "                pseudomask_img = Image.fromarray(binary_pseudomask) # convert to pil img\n",
    "                pseudomask_img.save(output_path_mask) # save as binary png\n",
    "\n",
    "                counter+= 1\n",
    "\n",
    "                if counter%10 ==0:\n",
    "                    print(f\"{counter} images produced\")\n",
    "    except: \n",
    "        files_generated = os.listdir(\"/Volumes/USB/Pseudomasks/Thresholded_CAM/newly_generated/images\")\n",
    "        missing_jpgs = missing_jpgs[~missing_jpgs.index.isin([f[:-4] for f in files_generated if f.endswith('.jpg')])]\n",
    "\n",
    "        dataset = ImageDataset(depth_dir, rgb_dir, missing_jpgs, im_size, normalize)\n",
    "        loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "        pseudomask_generator = Pseudomasks(\n",
    "            dataset, cam_threshold_factor, overlap_threshold,\n",
    "            snic_seeds, snic_compactness, finetuned = finetune, std_from_mean=0\n",
    "            )\n",
    "        pseudomask_generator.model = model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "        len(missing_jpgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
