{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadja/miniconda3/envs/torchvision/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/nadja/miniconda3/envs/torchvision/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <E03EDA44-89AE-3115-9796-62BA9E0E2EDE> /Users/nadja/miniconda3/envs/torchvision/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <2C8BF30B-D1BA-315D-BF33-9DF6F3757AB3> /Users/nadja/miniconda3/envs/torchvision/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnadja-flechner\u001b[0m (\u001b[33mnadjaflechner\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/nadja/Documents/UU/Thesis/Permafrost-Segmentation/Current_Version/pseudomasks/wandb/run-20240820_100547-lqnst9du</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nadjaflechner/Permafrost-Segmentation-Current_Version_pseudomasks/runs/lqnst9du' target=\"_blank\">easy-sunset-1</a></strong> to <a href='https://wandb.ai/nadjaflechner/Permafrost-Segmentation-Current_Version_pseudomasks' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nadjaflechner/Permafrost-Segmentation-Current_Version_pseudomasks' target=\"_blank\">https://wandb.ai/nadjaflechner/Permafrost-Segmentation-Current_Version_pseudomasks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nadjaflechner/Permafrost-Segmentation-Current_Version_pseudomasks/runs/lqnst9du' target=\"_blank\">https://wandb.ai/nadjaflechner/Permafrost-Segmentation-Current_Version_pseudomasks/runs/lqnst9du</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadja/miniconda3/envs/torchvision/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/nadja/miniconda3/envs/torchvision/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <E03EDA44-89AE-3115-9796-62BA9E0E2EDE> /Users/nadja/miniconda3/envs/torchvision/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <2C8BF30B-D1BA-315D-BF33-9DF6F3757AB3> /Users/nadja/miniconda3/envs/torchvision/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# Imports #\n",
    "############\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model.cnn_classifier import model_4D\n",
    "from model.finetune import FinetuneLoop\n",
    "from model.pseudomask import Pseudomasks\n",
    "from model.train import ClassifierTrainLoop\n",
    "from utils.data_modules import ImageDataset, TestSet, filter_dataset\n",
    "\n",
    "############\n",
    "# SWEEP 1 # \n",
    "############\n",
    "\n",
    "# model to be tested\n",
    "model = 'classification_model:v48'\n",
    "\n",
    "artifact_path = f'nadjaflechner/VGG_CAMs/{model}'\n",
    "testset_dir = '/Users/nadja/Documents/UU/Thesis/Data/Verified_GTs'\n",
    "depth_layer = 'hs'\n",
    "normalize = True\n",
    "finetune = False\n",
    "std_from_mean = 0\n",
    "\n",
    "\n",
    "test_set = TestSet(depth_layer, testset_dir, normalize)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=True, num_workers=1)\n",
    "\n",
    "pseudomask_generator = Pseudomasks(test_loader, None, None,\n",
    "                                    None, None, finetune, std_from_mean)\n",
    "\n",
    "api = wandb.Api()\n",
    "artifact = api.artifact(artifact_path, type='model')\n",
    "artifact_dir = artifact.download()\n",
    "state_dict = torch.load(f\"{artifact_dir}/model.pth\", map_location=torch.device('cpu'))\n",
    "pseudomask_generator.model_from_dict(state_dict)\n",
    "\n",
    "run = wandb.init(\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"model\": model,\n",
    "        \"normalize\": normalize\n",
    "        },\n",
    "        tags=['OnlyPseudomaskParams']\n",
    ")\n",
    "\n",
    "pseudomask_generator.cam_threshold = 0.8663095672480463\n",
    "pseudomask_generator.overlap_threshold = 0.4612206967723653\n",
    "pseudomask_generator.snic_seeds = 100\n",
    "pseudomask_generator.snic_compactness = 4\n",
    "\n",
    "pseudomask_generator.test_loop(test_loader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_only_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
