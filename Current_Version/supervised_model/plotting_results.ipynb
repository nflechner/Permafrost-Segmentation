{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "# Initialize wandb API\n",
    "api = wandb.Api()\n",
    "\n",
    "# Specify the artifact path\n",
    "artifact_path = 'nadjaflechner/Finetune_segformer_sweep/finetuned_segformer:v44'\n",
    "\n",
    "# Download the artifact\n",
    "artifact = api.artifact(artifact_path)\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "# Load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    \"nvidia/segformer-b5-finetuned-ade-640-640\",\n",
    "    num_labels=2,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(device)\n",
    "\n",
    "# Load the state dict\n",
    "state_dict = torch.load(f\"{artifact_dir}/model.pth\", map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# Initialize the image processor\n",
    "image_processor = SegformerImageProcessor(\n",
    "    image_mean=[74.90, 85.26, 80.06],\n",
    "    image_std=[15.05, 13.88, 12.01],\n",
    "    do_reduce_labels=False\n",
    ")\n",
    "\n",
    "def plot_segmentation(image_path):\n",
    "    # Load and process the image\n",
    "    image = Image.open(image_path)\n",
    "    pixel_values = image_processor(image, return_tensors=\"pt\").pixel_values.to(device)\n",
    "\n",
    "    # Generate prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(pixel_values=pixel_values)\n",
    "\n",
    "    # Process the output\n",
    "    logits = outputs.logits.cpu()\n",
    "    predicted_segmentation_map = image_processor.post_process_semantic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
    "    predicted_segmentation_map = predicted_segmentation_map.cpu().numpy()\n",
    "    # Create color segmentation\n",
    "    color_seg = np.zeros((predicted_segmentation_map.shape[0],\n",
    "                        predicted_segmentation_map.shape[1], 3), dtype=np.uint8) # height, width, 3\n",
    "\n",
    "    color = np.array([4, 250, 7])\n",
    "    color_seg[predicted_segmentation_map == 0, :] = color\n",
    "    # Convert to BGR\n",
    "    color_seg = color_seg[..., ::-1]\n",
    "\n",
    "    # Overlay segmentation on image\n",
    "    img = np.array(image) * 0.5 + color_seg * 0.5\n",
    "    img = img.astype(np.uint8)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Segmentation Result\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "image_path = \"path/to/your/image.jpg\"\n",
    "plot_segmentation(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original claude suggestion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "# Initialize wandb API\n",
    "api = wandb.Api()\n",
    "\n",
    "# Specify the artifact path\n",
    "artifact_path = 'nadjaflechner/Finetune_segformer_sweep/finetuned_segformer:v44'\n",
    "\n",
    "# Download the artifact\n",
    "artifact = api.artifact(artifact_path)\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "# Load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    \"nvidia/segformer-b5-finetuned-ade-640-640\",\n",
    "    num_labels=2,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(device)\n",
    "\n",
    "# Load the state dict\n",
    "state_dict = torch.load(f\"{artifact_dir}/model.pth\", map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# Initialize the image processor\n",
    "image_processor = SegformerImageProcessor(\n",
    "    image_mean=[74.90, 85.26, 80.06],\n",
    "    image_std=[15.05, 13.88, 12.01],\n",
    "    do_reduce_labels=False\n",
    ")\n",
    "\n",
    "def plot_segmentation(image_path):\n",
    "    # Load and process the image\n",
    "    image = Image.open(image_path)\n",
    "    pixel_values = image_processor(image, return_tensors=\"pt\").pixel_values.to(device)\n",
    "\n",
    "    # Generate prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(pixel_values=pixel_values)\n",
    "\n",
    "    # Process the output\n",
    "    logits = outputs.logits\n",
    "    upsampled_logits = torch.nn.functional.interpolate(\n",
    "        logits,\n",
    "        size=image.size[::-1],\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False\n",
    "    )\n",
    "    predicted_segmentation_map = upsampled_logits.argmax(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "    # Create color segmentation\n",
    "    color_seg = np.zeros((predicted_segmentation_map.shape[0],\n",
    "                          predicted_segmentation_map.shape[1], 3), dtype=np.uint8)\n",
    "    \n",
    "    color = np.array([4, 250, 7])  # Green color for the segmentation\n",
    "    color_seg[predicted_segmentation_map == 1] = color  # Assuming 1 is the target class\n",
    "    \n",
    "    # Overlay segmentation on image\n",
    "    img = np.array(image) * 0.5 + color_seg * 0.5\n",
    "    img = img.astype(np.uint8)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Segmentation Result\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "image_path = \"path/to/your/image.jpg\"\n",
    "plot_segmentation(image_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
