{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "## imports ##\n",
    "#############\n",
    "\n",
    "# libraries \n",
    "import geopandas as gpd\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "import os\n",
    "import json\n",
    "from shapely.geometry import box, Polygon\n",
    "import logging\n",
    "import random\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch\n",
    "\n",
    "##############\n",
    "## dataprep ##\n",
    "##############\n",
    "\n",
    "def get_RGB_match(DEM_name, original_tif_dir):\n",
    "\n",
    "    # Find the base name matching the DEM file\n",
    "    DEM_name = DEM_name[:-9] # remove _year.tif\n",
    "    north_kms = 0 if int(DEM_name[7:9]) < 50 else 5\n",
    "    east_kms = 0 if int(DEM_name[9:11]) < 50 else 5\n",
    "    RGB_name = f\"{DEM_name[:7]}{north_kms}{east_kms}\"\n",
    "\n",
    "    all_RGB_files = os.listdir(original_tif_dir)\n",
    "\n",
    "    newest_match = f\"{RGB_name}_0000\"\n",
    "    for file in all_RGB_files: \n",
    "        if str(file[:9]) == str(RGB_name) and int(file[10:14]) > int(newest_match[10:14]):\n",
    "            newest_match = file\n",
    "    return newest_match\n",
    "\n",
    "def tif_from_ruta(ruta_geometry):\n",
    "    minx_ruta = ruta_geometry.bounds[0]\n",
    "    miny_ruta = ruta_geometry.bounds[1]\n",
    "\n",
    "    miny = str(miny_ruta)[0:3]\n",
    "    minx = str(minx_ruta)[0:2]\n",
    "\n",
    "    if 0 <= int(str(miny_ruta)[3:5]) < 25:\n",
    "        km_siffran_y = '00'\n",
    "    elif 25 <= int(str(miny_ruta)[3:5]) < 50:\n",
    "        km_siffran_y = '25'\n",
    "    elif 50 <= int(str(miny_ruta)[3:5]) < 75:\n",
    "        km_siffran_y = '50'\n",
    "    elif 75 <= int(str(miny_ruta)[3:5]) < 100:\n",
    "        km_siffran_y = '75'\n",
    "\n",
    "    if 0 <= int(str(minx_ruta)[3:5]) < 25:\n",
    "        km_siffran_x = '00'\n",
    "    elif 25 <= int(str(minx_ruta)[3:5]) < 50:\n",
    "        km_siffran_x = '25'\n",
    "    elif 50 <= int(str(minx_ruta)[3:5]) < 75:\n",
    "        km_siffran_x = '50'\n",
    "    elif 75 <= int(str(minx_ruta)[3:5]) < 100:\n",
    "        km_siffran_x = '75'\n",
    "\n",
    "    year = 2018 # WHICH YEAR SHOULD IT BE??\n",
    "\n",
    "    filename = f\"{miny}_{minx}_{km_siffran_y}{km_siffran_x}_{year}.tif\"\n",
    "    return filename\n",
    "\n",
    "\n",
    "def filter_imgs(all_rutor_path, original_tif_dir):\n",
    "    all_rutor = gpd.read_file(all_rutor_path)\n",
    "    all_rutor['in_tif'] = all_rutor['geometry'].map(tif_from_ruta)\n",
    "    uniques = all_rutor.in_tif.unique()\n",
    "\n",
    "    dir_files = os.listdir(original_tif_dir)\n",
    "    only_tifs = [filename for filename in dir_files if filename[-4:] == \".tif\"]\n",
    "\n",
    "    # compare such only the part without the year. \n",
    "    only_tifs_noyear = [filename[:-8] for filename in only_tifs]\n",
    "    uniques_noyear = [filename[:-8] for filename in list(uniques)]\n",
    "\n",
    "    # check that all uniques are in only tifs\n",
    "    if not (set(list(uniques_noyear)).issubset(set(only_tifs_noyear))):\n",
    "        # logger.WARN(f\"at least one tif name generated from all_rutor was not found in the directory: {original_tif_dir}\")\n",
    "        print(f\"at least one tif name generated from all_rutor was not found in the directory\")\n",
    "        items_not_in_dir = [item for item in uniques_noyear if item not in only_tifs_noyear]\n",
    "        print(f\"items not in directory are: \\n {items_not_in_dir}\")\n",
    "\n",
    "    intersection = list(set(uniques_noyear) & set(only_tifs_noyear))\n",
    "\n",
    "    tifs_to_use = [filename for filename in only_tifs if filename[:-8] in intersection]\n",
    "\n",
    "    return tifs_to_use\n",
    "\n",
    "\n",
    "##############\n",
    "## cropping ##\n",
    "##############\n",
    "\n",
    "class Crop_tif_varsize():\n",
    "    \"\"\"\n",
    "    In: tif image to be cropped, and whole extent of 100x100 rutor\n",
    "    Returns: directory of one cropped tif per 100x100 ruta.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, RGB_name_code, RGB_img_path, hs_name_code, hs_img_path,\n",
    "                 DEM_name_code, DEM_img_path, rutor_path, destination_path, dims, logger, groundtruth_shapefile_path):\n",
    "\n",
    "        self.RGB_name_code = RGB_name_code\n",
    "        self.hs_name_code = hs_name_code\n",
    "        self.DEM_name_code = DEM_name_code\n",
    "        self.dimensions = dims\n",
    "        self.destination_path = destination_path\n",
    "        self.logger = logger\n",
    "        self.RGB_img_path = RGB_img_path\n",
    "        self.hs_img_path = hs_img_path\n",
    "        self.DEM_img_path = DEM_img_path\n",
    "        self.rutor_path = rutor_path\n",
    "        self.groundtruth_polygs = gpd.read_file(groundtruth_shapefile_path)\n",
    "        self.RGB_img = rasterio.open(RGB_img_path)\n",
    "        self.hs_img = rasterio.open(hs_img_path)\n",
    "        self.DEM_img = rasterio.open(DEM_img_path)\n",
    "        self.filtered_rutor = self.filter_rutor()\n",
    "\n",
    "    def forward(self):\n",
    "\n",
    "        # generate all possible polygons in the image of dim x dim \n",
    "        generated_polygons_all = self.generate_geoseries(self.hs_img.bounds, self.hs_img.crs, self.dimensions) \n",
    "        generated_polygons_palsa = self.palsa_polygons(generated_polygons_all)\n",
    "        positive_labels = self.crop_palsa_imgs(generated_polygons_palsa)\n",
    "        # aug_labels = self.crop_aug_imgs(generated_polygons_palsa)\n",
    "        negative_labels = self.crop_negatives(generated_polygons_all, generated_polygons_palsa)\n",
    "        all_labels = positive_labels | negative_labels \n",
    "        self.hs_img.close()\n",
    "        self.RGB_img.close()\n",
    "        self.DEM_img.close()\n",
    "        return all_labels\n",
    "\n",
    "    def filter_rutor(self):\n",
    "        # Find which 100x100 squares overlap with the current TIF\n",
    "        rutor = gpd.read_file(self.rutor_path)\n",
    "        image_polygon = box(*self.hs_img.bounds)\n",
    "        cropped_polygons = rutor[rutor.geometry.apply(lambda x: x.intersection(image_polygon).equals(x))]\n",
    "\n",
    "        return cropped_polygons\n",
    "    \n",
    "    def new_palsa_percentage(self, big_ruta, joined_df):\n",
    "        contained_rutor = joined_df.loc[joined_df['name'] == big_ruta]\n",
    "        total_pals_percentage = contained_rutor['PALS'].sum()\n",
    "        percentage_factor = self.dimensions **2 / 10000 # TODO check this part. was 100x100 = 10000 so should now be the same still. \n",
    "        palsa_percentage = total_pals_percentage / percentage_factor\n",
    "        return palsa_percentage\n",
    "    \n",
    "    def palsa_polygons(self, generated_polygons_all):\n",
    "\n",
    "        # if 100x100 meter is used, the original rutor are used\n",
    "        if self.dimensions == 100:\n",
    "            return self.filtered_rutor\n",
    "\n",
    "        # if not 100x100, find which polygons have palsa rutor in them\n",
    "        d = {'name': [i for i in range(len(generated_polygons_all))]}\n",
    "        generated_polygons_all_df = gpd.GeoDataFrame(d, geometry = generated_polygons_all, crs=generated_polygons_all.crs)\n",
    "\n",
    "        # Perform a spatial join between generated_polygons_all and filtered_rutor \n",
    "        joined_df = gpd.sjoin(generated_polygons_all_df, self.filtered_rutor, how='inner', op = 'contains')\n",
    "        covering_polygons_index = joined_df.index.unique() # find uniques\n",
    "        result_df = generated_polygons_all_df.loc[covering_polygons_index] # select polygons that cover a smaller polygon\n",
    "\n",
    "        # Generate palsa column in the resulting big ruta dataframe\n",
    "        result_df['PALS'] = result_df['name'].apply(lambda x: self.new_palsa_percentage(x, joined_df))\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    def generate_geoseries(self, bounds, crs, dims):\n",
    "\n",
    "        \"\"\"\n",
    "        Generates all dim x dim polygons present in the hillshade TIF.\n",
    "        \"\"\"\n",
    "\n",
    "        # height and width of new squares \n",
    "        square_dims = dims # 100x100 meters\n",
    "\n",
    "        # Calculate the number of segments in each dimension (tif width // desired width in pixels!)\n",
    "        segments_x = 2500 // square_dims # for depth data its 2500\n",
    "        segments_y = 2500 // square_dims\n",
    "\n",
    "        # Create an empty list to store the polygons\n",
    "        polygons = []\n",
    "\n",
    "        # Iterate over the segments\n",
    "        for i in range(segments_y):\n",
    "            for j in range(segments_x):\n",
    "                # Calculate the coordinates of the segment\n",
    "                left = bounds.left + j * square_dims\n",
    "                bottom = bounds.bottom + i * square_dims\n",
    "                right = left + square_dims\n",
    "                top = bottom + square_dims\n",
    "\n",
    "                # Create a polygon for the segment\n",
    "                polygon = Polygon([(right, bottom), (left, bottom), (left, top), (right, top), (right, bottom)])\n",
    "\n",
    "                # Append the polygon to the list\n",
    "                polygons.append(polygon)\n",
    "\n",
    "        # Create a GeoSeries from the list of polygons\n",
    "        return gpd.GeoSeries(polygons, crs=crs)\n",
    "\n",
    "    def make_crop(self, img, polygon, output_path):\n",
    "        # Crop the TIF file using the polygon\n",
    "        cropped_data, cropped_transform = mask(img, [polygon], crop=True)\n",
    "\n",
    "        # Update the metadata for the cropped TIF\n",
    "        cropped_meta = img.meta.copy()\n",
    "        cropped_meta.update({\"driver\": \"GTiff\",\n",
    "                            \"height\": cropped_data.shape[1],\n",
    "                            \"width\": cropped_data.shape[2],\n",
    "                            \"transform\": cropped_transform})\n",
    "\n",
    "        # Save the cropped TIF file with a unique name\n",
    "        with rasterio.open(output_path, \"w\", **cropped_meta) as dest:\n",
    "            dest.write(cropped_data)\n",
    "\n",
    "    def make_ground_truth(self, intersections, img_crop_path, gt_path):\n",
    "\n",
    "        # use previously created cropped image\n",
    "        cropped_img = rasterio.open(img_crop_path)\n",
    "        masked_data, _ = mask(cropped_img, [polyg for polyg in intersections.geometry])\n",
    "\n",
    "        with rasterio.open(gt_path, \"w\", **cropped_img.meta.copy()) as dest:\n",
    "            dest.write(masked_data)\n",
    "\n",
    "\n",
    "    def crop_palsa_imgs(self, palsa_rutor):\n",
    "\n",
    "        \"\"\"\n",
    "        Crop TIF according to the polygons containing palsa. \n",
    "        \"\"\"\n",
    "\n",
    "        cropped_tifs_percentages = {}\n",
    "        # Iterate over each polygon in the GeoDataFrame\n",
    "        for idx, percentage, polygon in zip(palsa_rutor.index, palsa_rutor.PALS, palsa_rutor.geometry):\n",
    "\n",
    "            # see if there is an overlap with ground truths:\n",
    "            polyg_df = palsa_rutor.iloc[[idx]]\n",
    "            intersections = gpd.overlay(self.groundtruth_polygs, polyg_df, how='intersection')\n",
    "\n",
    "            # only crop if theres a ground truth overlap\n",
    "            if not intersections.empty:\n",
    "\n",
    "                hs_path = f'{self.destination_path}/hs/{self.hs_name_code}_crop_{idx}.tif'\n",
    "                RGB_path = f'{self.destination_path}/rgb/{self.hs_name_code}_crop_{idx}.tif'\n",
    "                DEM_path = f'{self.destination_path}/dem/{self.hs_name_code}_crop_{idx}.tif'\n",
    "                gt_path = f'{self.destination_path}/groundtruth_mask/{self.hs_name_code}_crop_{idx}.tif'\n",
    "\n",
    "                # crop hillshade and RGB according to same polygons\n",
    "                self.make_crop(self.hs_img, polygon, hs_path) \n",
    "                self.make_crop(self.RGB_img, polygon, RGB_path)\n",
    "                self.make_crop(self.DEM_img, polygon, DEM_path)\n",
    "\n",
    "                # generate ground truth\n",
    "                self.make_ground_truth(intersections, hs_path, gt_path)\n",
    "                \n",
    "                # Write the corresponding percentage to a dictionary as label \n",
    "                cropped_tifs_percentages[f\"{self.hs_name_code}_crop_{idx}\"] = percentage\n",
    "\n",
    "        return cropped_tifs_percentages\n",
    "\n",
    "    def crop_negatives(self, generated_polygons_all, generated_polygons_palsa):\n",
    "\n",
    "        \"\"\"\n",
    "        Generates negative samples. Equal amount of negative as positive samples are\n",
    "        taken from each image such that the final dataset is 50/50 positive and negative. \n",
    "\n",
    "            1) split the whole TIF into 100x100m polygons.\n",
    "            2) filter out the areas containing palsa (positive samples)\n",
    "            3) randomly sample as many negative samples as positive samples from that image\n",
    "            4) crop the TIF according to the sampled areas and write locally\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # filter out the squares with palsa \n",
    "        positives_mask = ~generated_polygons_all.isin(generated_polygons_palsa.geometry)\n",
    "        all_negatives = generated_polygons_all[positives_mask]\n",
    "\n",
    "        # randomly sample \n",
    "        sample_size = int(len(generated_polygons_palsa)) # based on number of positive samples \n",
    "        if sample_size <= len(all_negatives): # default case\n",
    "            negative_samples = all_negatives.sample(n=sample_size) # sample randomly\n",
    "        else:\n",
    "            self.logger.info('Exception occurred! Number of positive samples > 1/2 image. Training set now contains fewer negative than positive samples.')\n",
    "            negative_samples = all_negatives\n",
    "\n",
    "        cropped_tifs_percentages = {}\n",
    "        # Iterate over each polygon in the GeoDataFrame\n",
    "        for idx, polygon in enumerate(negative_samples.geometry):\n",
    "            # Crop the TIF file using the polygon\n",
    "            hs_path = f'{self.destination_path}/hs/{self.hs_name_code}_negcrop_{idx}.tif'\n",
    "            RGB_path = f'{self.destination_path}/rgb/{self.hs_name_code}_negcrop_{idx}.tif'\n",
    "            DEM_path = f'{self.destination_path}/dem/{self.hs_name_code}_negcrop_{idx}.tif'\n",
    "            gt_path = f'{self.destination_path}/groundtruth_mask/{self.hs_name_code}_crop_{idx}.tif'\n",
    "\n",
    "            # crop hillshade and RGB according to same polygons\n",
    "            self.make_crop(self.hs_img, polygon, hs_path) \n",
    "            self.make_crop(self.RGB_img, polygon, RGB_path)\n",
    "            self.make_crop(self.DEM_img, polygon, DEM_path)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "            # GENERATE NEGATIVE GROUND TRUTHS\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "            # Write the corresponding percentage to a dictionary as label \n",
    "            cropped_tifs_percentages[f\"{self.hs_name_code}_negcrop_{idx}\"] = 0\n",
    "\n",
    "        return cropped_tifs_percentages\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 16:51:51 - Imports successful \n",
      "\n",
      "2024-06-04 16:51:51 - Configurations were loaded \n",
      "\n",
      "2024-06-04 16:51:51 - 8 TIF paths have been loaded! \n",
      "\n",
      "2024-06-04 16:51:51 - Starting to generate training samples from TIFs.. \n",
      "\n",
      "/tmp/ipykernel_43892/2319119357.py:88: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  new_labels = cropping.forward()\n",
      "2024-06-04 16:51:58 - Generated training samples from image 1/8 \n",
      "\n",
      "/tmp/ipykernel_43892/2319119357.py:88: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  new_labels = cropping.forward()\n",
      "2024-06-04 16:52:05 - RGB or DEM match for 746_57_5050_2015.tif not found \n",
      "\n",
      "/tmp/ipykernel_43892/2319119357.py:88: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  new_labels = cropping.forward()\n",
      "2024-06-04 16:52:13 - Generated training samples from image 3/8 \n",
      "\n",
      "/tmp/ipykernel_43892/2319119357.py:88: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  new_labels = cropping.forward()\n",
      "2024-06-04 16:52:20 - RGB or DEM match for 746_57_5075_2015.tif not found \n",
      "\n",
      "/tmp/ipykernel_43892/2319119357.py:88: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  new_labels = cropping.forward()\n",
      "2024-06-04 16:52:27 - Generated training samples from image 5/8 \n",
      "\n",
      "/tmp/ipykernel_43892/2319119357.py:88: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  new_labels = cropping.forward()\n",
      "2024-06-04 16:52:34 - RGB or DEM match for 746_57_5025_2015.tif not found \n",
      "\n",
      "/tmp/ipykernel_43892/2319119357.py:88: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  new_labels = cropping.forward()\n",
      "2024-06-04 16:52:42 - RGB or DEM match for 749_68_2550_2014.tif not found \n",
      "\n",
      "/tmp/ipykernel_43892/2319119357.py:88: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  new_labels = cropping.forward()\n",
      "2024-06-04 16:52:49 - RGB or DEM match for 746_57_2525_2015.tif not found \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following images had no rgb match: \n",
      " ['746_57_5050_2015.tif', '746_57_5075_2015.tif', '746_57_5025_2015.tif', '749_68_2550_2014.tif', '746_57_2525_2015.tif']\n",
      "number of images where script failed: \n",
      " 5\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "## imports ##\n",
    "#############\n",
    "\n",
    "# libraries \n",
    "import geopandas as gpd\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# functions \n",
    "# from functions import get_RGB_match, Crop_tif_varsize, filter_imgs\n",
    "\n",
    "##################\n",
    "## setup logger ##\n",
    "##################\n",
    "\n",
    "logger = logging.getLogger('my_logger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Setup logger\n",
    "ch = logging.StreamHandler() # create console handler\n",
    "ch.setLevel(logging.DEBUG) # set level to debug\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(message)s \\n\", \"%Y-%m-%d %H:%M:%S\") # create formatter\n",
    "ch.setFormatter(formatter) # add formatter to ch\n",
    "logger.addHandler(ch) # add ch to logger\n",
    "\n",
    "logger.info('Imports successful')\n",
    "\n",
    "##################\n",
    "## load configs ##\n",
    "##################\n",
    "\n",
    "config_path = os.path.join(os.getcwd(), 'configs.json')\n",
    "with open(config_path, 'r') as config_file:\n",
    "    configs = json.load(config_file)\n",
    "\n",
    "# load paths from configs \n",
    "config_paths = configs.get('paths', {}) \n",
    "palsa_shapefile_path = config_paths.get('palsa_shapefile_path') # load shapefile path\n",
    "groundtruth_shapefile_path = config_paths.get('groundtruth_shapefile_path') # load shapefile path\n",
    "save_crops_dir = config_paths.get('save_crops_dir') # load directory with all tifs\n",
    "RGB_tif_dir = config_paths.get('RGB_tif_dir') # load directory with all tifs\n",
    "hillshade_tif_dir = config_paths.get('hillshade_tif_dir') # load directory with all tifs\n",
    "DEM_tif_dir = config_paths.get('DEM_tif_dir') # load directory with all tifs\n",
    "\n",
    "config_img = configs.get('image_info', {}) \n",
    "dims = int(config_img.get('meters_per_axis')) \n",
    "\n",
    "logger.info('Configurations were loaded')\n",
    "\n",
    "##########\n",
    "## code ##\n",
    "##########\n",
    "\n",
    "# Filter hillshade data so only those containing a ground truth polygon remain\n",
    "hillshade_filenames = filter_imgs(groundtruth_shapefile_path, hillshade_tif_dir) \n",
    "logger.info(f'{len(hillshade_filenames)} TIF paths have been loaded!')\n",
    "\n",
    "# Loop over hillshade images to generate the crops. \n",
    "logger.info('Starting to generate training samples from TIFs..')\n",
    "labels = {}\n",
    "not_found = []\n",
    "for idx, hs_img_name in enumerate(hillshade_filenames):\n",
    "    # grab corresponding RGB image (matching the hillshade)\n",
    "    try:\n",
    "        RGB_tif_name = get_RGB_match(hs_img_name, RGB_tif_dir) \n",
    "        RGB_img_name_code = RGB_tif_name.split('.')[0]\n",
    "        RGB_img_path = os.path.join(RGB_tif_dir, RGB_tif_name)\n",
    "\n",
    "        hs_img_name_code = hs_img_name.split('.')[0]\n",
    "        hs_img_path = os.path.join(hillshade_tif_dir, hs_img_name)\n",
    "\n",
    "        DEM_img_name_code = hs_img_name.split('.')[0]\n",
    "        DEM_img_path = os.path.join(DEM_tif_dir, hs_img_name)\n",
    "\n",
    "        cropping = Crop_tif_varsize(RGB_img_name_code, RGB_img_path, hs_img_name_code, \n",
    "                                    hs_img_path, DEM_img_name_code, DEM_img_path, \n",
    "                                    palsa_shapefile_path, save_crops_dir, dims, logger, groundtruth_shapefile_path)\n",
    "        \n",
    "        # Run the cropping script\n",
    "        new_labels = cropping.forward()\n",
    "        labels = labels | new_labels\n",
    "        logger.info(f'Generated training samples from image {idx+1}/{len(hillshade_filenames)}')\n",
    "    except: \n",
    "        logger.info(f'RGB or DEM match for {hs_img_name} not found')\n",
    "        not_found.append(hs_img_name)\n",
    "\n",
    "print(f'The following images had no rgb match: \\n {not_found}')\n",
    "print(f'number of images where script failed: \\n {len(not_found)}')\n",
    "\n",
    "label_df = pd.DataFrame.from_dict(labels, orient='index', columns = ['palsa_percentage'])\n",
    "label_df.to_csv(os.path.join(save_crops_dir, \"palsa_labels.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "palsa_env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
