{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# Imports #\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from utils import ImageDataset, SaveFeatures, accuracy, imshow_transform\n",
    "from custom_model import model_4D\n",
    "from torch.autograd import Variable\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imshow\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt \n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# Hyperparameters #\n",
    "\n",
    "n_samples = 10000\n",
    "n_samples_train = int(round(n_samples*0.8))\n",
    "n_samples_val = int(round(n_samples*0.2))\n",
    "batch_size = 20\n",
    "current_computer =  \"ubuntu\" # \"macbook\" \n",
    "layers_to_freeze = 0\n",
    "lr = 0.0001\n",
    "weight_decay=0.04\n",
    "num_epochs = 15\n",
    "im_size = 200\n",
    "min_palsa_positive_samples = 10\n",
    "\n",
    "\n",
    "##########################\n",
    "# log hyperparams to w&b #\n",
    "\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"VGG_CAMs\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"epochs\": num_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"n_samples\": n_samples,\n",
    "        \"layers_to_freeze\": layers_to_freeze,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"im_size\": im_size,\n",
    "        \"min_palsa_positive_samples\": min_palsa_positive_samples\n",
    "    },\n",
    "    tags=['4D', 'LRScheduler', 'MSELoss', 'TrainFromScratch']\n",
    ")\n",
    "\n",
    "#############\n",
    "# Load data #\n",
    "\n",
    "if current_computer == \"ubuntu\":\n",
    "    hs_dir = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/hs'\n",
    "    RGB_dir = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/rgb'\n",
    "    labels_file = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/palsa_labels.csv'\n",
    "elif current_computer == \"macbook\":\n",
    "    hs_dir = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/hs'\n",
    "    RGB_dir = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/rgb'\n",
    "    labels_file = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/palsa_labels.csv'\n",
    "\n",
    "# Load the labels from the CSV file\n",
    "if min_palsa_positive_samples > 0:\n",
    "    labels_df = pd.read_csv(labels_file, index_col=0)\n",
    "    drop_range = labels_df[ (labels_df['palsa_percentage'] > 0) & (labels_df['palsa_percentage'] < min_palsa_positive_samples) ].index\n",
    "\n",
    "    labels_df.drop(drop_range, inplace=True)\n",
    "    labels_df = labels_df.head(n_samples)\n",
    "else: \n",
    "    labels_df = pd.read_csv(labels_file, index_col=0).head(n_samples)\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df = labels_df.head(n_samples_train)\n",
    "val_df = labels_df.drop(train_df.index)\n",
    "\n",
    "# Create the datasets and data loaders\n",
    "train_dataset = ImageDataset(hs_dir, RGB_dir, train_df, im_size)\n",
    "val_dataset = ImageDataset(hs_dir, RGB_dir, val_df, im_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = model_4D()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.92)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "##################\n",
    "# Training loop #\n",
    "\n",
    "# adapted from https://github.com/tony-mtz/CAM/blob/master/network/net.py\n",
    "\n",
    "mean_train_losses = []\n",
    "mean_val_losses = []\n",
    "\n",
    "mean_train_acc = []\n",
    "mean_val_acc = []\n",
    "\n",
    "max_val_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('EPOCH: ',epoch+1)\n",
    "\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    train_batch_count = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):     \n",
    "\n",
    "        # load images and labels \n",
    "        images = Variable(images).to(device)  \n",
    "        labels = Variable(labels.long()).to(device)  \n",
    "\n",
    "        # train batch   \n",
    "        outputs = model(images) \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "\n",
    "        # calculate loss and accuracy\n",
    "        train_acc.append(accuracy(outputs, labels.long()))\n",
    "        running_loss += loss.item()\n",
    "        train_batch_count += 1\n",
    "\n",
    "    del images\n",
    "    del labels\n",
    "    del outputs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()\n",
    "    val_batch_count = 0\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(val_loader):     \n",
    "            # load images and labels \n",
    "            images = Variable(images).to(device)  \n",
    "            labels = Variable(labels.long()).to(device)  \n",
    "            outputs = model(images) \n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            val_acc.append(accuracy(outputs, labels))\n",
    "            val_running_loss += loss.item()\n",
    "            val_batch_count +=1\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    del images\n",
    "    del labels\n",
    "    del outputs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # update losses and accuracies \n",
    "\n",
    "    mean_train_acc.append(np.mean(train_acc))\n",
    "    mean_val_acc.append(np.mean(val_acc))\n",
    "    mean_train_losses.append(running_loss/train_batch_count)\n",
    "    mean_val_losses.append(val_running_loss/val_batch_count)\n",
    "\n",
    "    wandb.log({\"train_accuracy\": np.mean(train_acc)})\n",
    "    wandb.log({\"val_accuracy\": np.mean(val_acc)})\n",
    "    wandb.log({\"train_loss\": running_loss/train_batch_count})\n",
    "    wandb.log({\"val_loss\": val_running_loss/val_batch_count})\n",
    "\n",
    "    if np.mean(val_acc) > max_val_acc:\n",
    "        best_model = model.state_dict()\n",
    "        max_val_acc = np.mean(val_acc)\n",
    "\n",
    "\n",
    "torch.save(best_model, '/home/nadjaflechner/models/model.pth')\n",
    "artifact = wandb.Artifact('model', type='model')\n",
    "artifact.add_file('/home/nadjaflechner/models/model.pth')\n",
    "run.log_artifact(artifact)\n",
    "\n",
    "##########################\n",
    "# plot loss and accuracy #\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,5))\n",
    "\n",
    "ax1.plot([i for i in range(num_epochs)], mean_val_losses, c = 'b', label = 'val loss')\n",
    "ax1.plot([i for i in range(num_epochs)], mean_train_losses, c = 'r', label = 'train loss')\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_xticks(range(0,num_epochs+1,5))\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot([i for i in range(num_epochs)], mean_val_acc, c = 'b', label = 'val accuracy')\n",
    "ax2.plot([i for i in range(num_epochs)], mean_train_acc, c = 'r', label = 'train accuracy')\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_xticks(range(0,num_epochs+1,5))\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "wandb.log({'model_performance': wandb.Image(fig)})\n",
    "\n",
    "####################\n",
    "# generating CAMs #\n",
    "\n",
    "#change batch size to 1 to grab one image at a time\n",
    "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, \n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "# Load best model to produce CAMs with\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "# Save 10 palsa images\n",
    "palsa_imgs = 0\n",
    "for palsa_cam in range(100):\n",
    "    im, lab = next(iter(valid_loader))\n",
    "\n",
    "    #get the last convolution\n",
    "    sf = SaveFeatures(model.features[-4])\n",
    "    model.eval()\n",
    "\n",
    "    if lab == 1:\n",
    "        palsa_imgs+= 1\n",
    "        im = Variable(im).to(device)\n",
    "        outputs = model(im).to(device)\n",
    "        res = torch.argmax(outputs.data).cpu().detach().numpy()\n",
    "\n",
    "        # generate CAM\n",
    "        sf.remove()\n",
    "        arr = sf.features.cpu().detach().numpy()\n",
    "        arr1 = arr[0]\n",
    "        ans_nopalsa = np.dot(np.rollaxis(arr1,0,3), [1,0])\n",
    "        ans_palsa = np.dot(np.rollaxis(arr1,0,3), [0,1])\n",
    "\n",
    "        if res==1:\n",
    "            CAM = resize(ans_palsa, (im_size*2,im_size*2))\n",
    "        else:\n",
    "            CAM = resize(ans_nopalsa, (im_size*2,im_size*2))\n",
    "\n",
    "        # Plot image with CAM\n",
    "        cpu_img = im.squeeze().cpu().detach().permute(1,2,0).long().numpy()\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,7))\n",
    "\n",
    "        ax1.imshow(cpu_img)\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        ax1.set_title(f'original image')\n",
    "\n",
    "        ax2.imshow(cpu_img)\n",
    "        ax2.imshow(CAM, alpha=.4, cmap='jet')\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        ax2.set_title('image with CAM')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        wandb.log({'generated_CAM': fig})\n",
    "\n",
    "    if palsa_imgs == 20:\n",
    "        break\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "del images\n",
    "del labels\n",
    "del outputs\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# Hyperparameters #\n",
    "\n",
    "n_samples = 10000\n",
    "n_samples_train = int(round(n_samples*0.8))\n",
    "n_samples_val = int(round(n_samples*0.2))\n",
    "batch_size = 20\n",
    "current_computer =  \"ubuntu\" # \"macbook\" \n",
    "layers_to_freeze = 0\n",
    "lr = 0.001\n",
    "weight_decay=0.04\n",
    "num_epochs = 15\n",
    "im_size = 200\n",
    "min_palsa_positive_samples = 10\n",
    "\n",
    "\n",
    "##########################\n",
    "# log hyperparams to w&b #\n",
    "\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"VGG_CAMs\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"epochs\": num_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"n_samples\": n_samples,\n",
    "        \"layers_to_freeze\": layers_to_freeze,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"im_size\": im_size,\n",
    "        \"min_palsa_positive_samples\": min_palsa_positive_samples\n",
    "    },\n",
    "    tags=['4D', 'LRScheduler', 'MSELoss', 'TrainFromScratch']\n",
    ")\n",
    "\n",
    "#############\n",
    "# Load data #\n",
    "\n",
    "if current_computer == \"ubuntu\":\n",
    "    hs_dir = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/hs'\n",
    "    RGB_dir = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/rgb'\n",
    "    labels_file = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/palsa_labels.csv'\n",
    "elif current_computer == \"macbook\":\n",
    "    hs_dir = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/hs'\n",
    "    RGB_dir = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/rgb'\n",
    "    labels_file = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/palsa_labels.csv'\n",
    "\n",
    "# Load the labels from the CSV file\n",
    "if min_palsa_positive_samples > 0:\n",
    "    labels_df = pd.read_csv(labels_file, index_col=0)\n",
    "    drop_range = labels_df[ (labels_df['palsa_percentage'] > 0) & (labels_df['palsa_percentage'] < min_palsa_positive_samples) ].index\n",
    "\n",
    "    labels_df.drop(drop_range, inplace=True)\n",
    "    labels_df = labels_df.head(n_samples)\n",
    "else: \n",
    "    labels_df = pd.read_csv(labels_file, index_col=0).head(n_samples)\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df = labels_df.head(n_samples_train)\n",
    "val_df = labels_df.drop(train_df.index)\n",
    "\n",
    "# Create the datasets and data loaders\n",
    "train_dataset = ImageDataset(hs_dir, RGB_dir, train_df, im_size)\n",
    "val_dataset = ImageDataset(hs_dir, RGB_dir, val_df, im_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = model_4D()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.92)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "##################\n",
    "# Training loop #\n",
    "\n",
    "# adapted from https://github.com/tony-mtz/CAM/blob/master/network/net.py\n",
    "\n",
    "mean_train_losses = []\n",
    "mean_val_losses = []\n",
    "\n",
    "mean_train_acc = []\n",
    "mean_val_acc = []\n",
    "\n",
    "max_val_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('EPOCH: ',epoch+1)\n",
    "\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    train_batch_count = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):     \n",
    "\n",
    "        # load images and labels \n",
    "        images = Variable(images).to(device)  \n",
    "        labels = Variable(labels.long()).to(device)  \n",
    "\n",
    "        # train batch   \n",
    "        outputs = model(images) \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "\n",
    "        # calculate loss and accuracy\n",
    "        train_acc.append(accuracy(outputs, labels.long()))\n",
    "        running_loss += loss.item()\n",
    "        train_batch_count += 1\n",
    "\n",
    "    del images\n",
    "    del labels\n",
    "    del outputs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()\n",
    "    val_batch_count = 0\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(val_loader):     \n",
    "            # load images and labels \n",
    "            images = Variable(images).to(device)  \n",
    "            labels = Variable(labels.long()).to(device)  \n",
    "            outputs = model(images) \n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            val_acc.append(accuracy(outputs, labels))\n",
    "            val_running_loss += loss.item()\n",
    "            val_batch_count +=1\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    del images\n",
    "    del labels\n",
    "    del outputs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # update losses and accuracies \n",
    "\n",
    "    mean_train_acc.append(np.mean(train_acc))\n",
    "    mean_val_acc.append(np.mean(val_acc))\n",
    "    mean_train_losses.append(running_loss/train_batch_count)\n",
    "    mean_val_losses.append(val_running_loss/val_batch_count)\n",
    "\n",
    "    wandb.log({\"train_accuracy\": np.mean(train_acc)})\n",
    "    wandb.log({\"val_accuracy\": np.mean(val_acc)})\n",
    "    wandb.log({\"train_loss\": running_loss/train_batch_count})\n",
    "    wandb.log({\"val_loss\": val_running_loss/val_batch_count})\n",
    "\n",
    "    if np.mean(val_acc) > max_val_acc:\n",
    "        best_model = model.state_dict()\n",
    "        max_val_acc = np.mean(val_acc)\n",
    "\n",
    "\n",
    "torch.save(best_model, '/home/nadjaflechner/models/model.pth')\n",
    "artifact = wandb.Artifact('model', type='model')\n",
    "artifact.add_file('/home/nadjaflechner/models/model.pth')\n",
    "run.log_artifact(artifact)\n",
    "\n",
    "##########################\n",
    "# plot loss and accuracy #\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,5))\n",
    "\n",
    "ax1.plot([i for i in range(num_epochs)], mean_val_losses, c = 'b', label = 'val loss')\n",
    "ax1.plot([i for i in range(num_epochs)], mean_train_losses, c = 'r', label = 'train loss')\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_xticks(range(0,num_epochs+1,5))\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot([i for i in range(num_epochs)], mean_val_acc, c = 'b', label = 'val accuracy')\n",
    "ax2.plot([i for i in range(num_epochs)], mean_train_acc, c = 'r', label = 'train accuracy')\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_xticks(range(0,num_epochs+1,5))\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "wandb.log({'model_performance': wandb.Image(fig)})\n",
    "\n",
    "####################\n",
    "# generating CAMs #\n",
    "\n",
    "#change batch size to 1 to grab one image at a time\n",
    "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, \n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "# Load best model to produce CAMs with\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "# Save 10 palsa images\n",
    "palsa_imgs = 0\n",
    "for palsa_cam in range(100):\n",
    "    im, lab = next(iter(valid_loader))\n",
    "\n",
    "    #get the last convolution\n",
    "    sf = SaveFeatures(model.features[-4])\n",
    "    model.eval()\n",
    "\n",
    "    if lab == 1:\n",
    "        palsa_imgs+= 1\n",
    "        im = Variable(im).to(device)\n",
    "        outputs = model(im).to(device)\n",
    "        res = torch.argmax(outputs.data).cpu().detach().numpy()\n",
    "\n",
    "        # generate CAM\n",
    "        sf.remove()\n",
    "        arr = sf.features.cpu().detach().numpy()\n",
    "        arr1 = arr[0]\n",
    "        ans_nopalsa = np.dot(np.rollaxis(arr1,0,3), [1,0])\n",
    "        ans_palsa = np.dot(np.rollaxis(arr1,0,3), [0,1])\n",
    "\n",
    "        if res==1:\n",
    "            CAM = resize(ans_palsa, (im_size*2,im_size*2))\n",
    "        else:\n",
    "            CAM = resize(ans_nopalsa, (im_size*2,im_size*2))\n",
    "\n",
    "        # Plot image with CAM\n",
    "        cpu_img = im.squeeze().cpu().detach().permute(1,2,0).long().numpy()\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,7))\n",
    "\n",
    "        ax1.imshow(cpu_img)\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        ax1.set_title(f'original image')\n",
    "\n",
    "        ax2.imshow(cpu_img)\n",
    "        ax2.imshow(CAM, alpha=.4, cmap='jet')\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        ax2.set_title('image with CAM')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        wandb.log({'generated_CAM': fig})\n",
    "\n",
    "    if palsa_imgs == 20:\n",
    "        break\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "del images\n",
    "del labels\n",
    "del outputs\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# Hyperparameters #\n",
    "\n",
    "n_samples = 10000\n",
    "n_samples_train = int(round(n_samples*0.8))\n",
    "n_samples_val = int(round(n_samples*0.2))\n",
    "batch_size = 20\n",
    "current_computer =  \"ubuntu\" # \"macbook\" \n",
    "layers_to_freeze = 0\n",
    "lr = 0.00001\n",
    "weight_decay=0.08\n",
    "num_epochs = 15\n",
    "im_size = 200\n",
    "min_palsa_positive_samples = 10\n",
    "\n",
    "\n",
    "##########################\n",
    "# log hyperparams to w&b #\n",
    "\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"VGG_CAMs\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"epochs\": num_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"n_samples\": n_samples,\n",
    "        \"layers_to_freeze\": layers_to_freeze,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"im_size\": im_size,\n",
    "        \"min_palsa_positive_samples\": min_palsa_positive_samples\n",
    "    },\n",
    "    tags=['4D', 'LRScheduler', 'MSELoss', 'TrainFromScratch']\n",
    ")\n",
    "\n",
    "#############\n",
    "# Load data #\n",
    "\n",
    "if current_computer == \"ubuntu\":\n",
    "    hs_dir = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/hs'\n",
    "    RGB_dir = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/rgb'\n",
    "    labels_file = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/palsa_labels.csv'\n",
    "elif current_computer == \"macbook\":\n",
    "    hs_dir = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/hs'\n",
    "    RGB_dir = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/rgb'\n",
    "    labels_file = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/palsa_labels.csv'\n",
    "\n",
    "# Load the labels from the CSV file\n",
    "if min_palsa_positive_samples > 0:\n",
    "    labels_df = pd.read_csv(labels_file, index_col=0)\n",
    "    drop_range = labels_df[ (labels_df['palsa_percentage'] > 0) & (labels_df['palsa_percentage'] < min_palsa_positive_samples) ].index\n",
    "\n",
    "    labels_df.drop(drop_range, inplace=True)\n",
    "    labels_df = labels_df.head(n_samples)\n",
    "else: \n",
    "    labels_df = pd.read_csv(labels_file, index_col=0).head(n_samples)\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df = labels_df.head(n_samples_train)\n",
    "val_df = labels_df.drop(train_df.index)\n",
    "\n",
    "# Create the datasets and data loaders\n",
    "train_dataset = ImageDataset(hs_dir, RGB_dir, train_df, im_size)\n",
    "val_dataset = ImageDataset(hs_dir, RGB_dir, val_df, im_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = model_4D()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.92)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "##################\n",
    "# Training loop #\n",
    "\n",
    "# adapted from https://github.com/tony-mtz/CAM/blob/master/network/net.py\n",
    "\n",
    "mean_train_losses = []\n",
    "mean_val_losses = []\n",
    "\n",
    "mean_train_acc = []\n",
    "mean_val_acc = []\n",
    "\n",
    "max_val_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('EPOCH: ',epoch+1)\n",
    "\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    train_batch_count = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):     \n",
    "\n",
    "        # load images and labels \n",
    "        images = Variable(images).to(device)  \n",
    "        labels = Variable(labels.long()).to(device)  \n",
    "\n",
    "        # train batch   \n",
    "        outputs = model(images) \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "\n",
    "        # calculate loss and accuracy\n",
    "        train_acc.append(accuracy(outputs, labels.long()))\n",
    "        running_loss += loss.item()\n",
    "        train_batch_count += 1\n",
    "\n",
    "    del images\n",
    "    del labels\n",
    "    del outputs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()\n",
    "    val_batch_count = 0\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(val_loader):     \n",
    "            # load images and labels \n",
    "            images = Variable(images).to(device)  \n",
    "            labels = Variable(labels.long()).to(device)  \n",
    "            outputs = model(images) \n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            val_acc.append(accuracy(outputs, labels))\n",
    "            val_running_loss += loss.item()\n",
    "            val_batch_count +=1\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    del images\n",
    "    del labels\n",
    "    del outputs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # update losses and accuracies \n",
    "\n",
    "    mean_train_acc.append(np.mean(train_acc))\n",
    "    mean_val_acc.append(np.mean(val_acc))\n",
    "    mean_train_losses.append(running_loss/train_batch_count)\n",
    "    mean_val_losses.append(val_running_loss/val_batch_count)\n",
    "\n",
    "    wandb.log({\"train_accuracy\": np.mean(train_acc)})\n",
    "    wandb.log({\"val_accuracy\": np.mean(val_acc)})\n",
    "    wandb.log({\"train_loss\": running_loss/train_batch_count})\n",
    "    wandb.log({\"val_loss\": val_running_loss/val_batch_count})\n",
    "\n",
    "    if np.mean(val_acc) > max_val_acc:\n",
    "        best_model = model.state_dict()\n",
    "        max_val_acc = np.mean(val_acc)\n",
    "\n",
    "\n",
    "torch.save(best_model, '/home/nadjaflechner/models/model.pth')\n",
    "artifact = wandb.Artifact('model', type='model')\n",
    "artifact.add_file('/home/nadjaflechner/models/model.pth')\n",
    "run.log_artifact(artifact)\n",
    "\n",
    "##########################\n",
    "# plot loss and accuracy #\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,5))\n",
    "\n",
    "ax1.plot([i for i in range(num_epochs)], mean_val_losses, c = 'b', label = 'val loss')\n",
    "ax1.plot([i for i in range(num_epochs)], mean_train_losses, c = 'r', label = 'train loss')\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_xticks(range(0,num_epochs+1,5))\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot([i for i in range(num_epochs)], mean_val_acc, c = 'b', label = 'val accuracy')\n",
    "ax2.plot([i for i in range(num_epochs)], mean_train_acc, c = 'r', label = 'train accuracy')\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_xticks(range(0,num_epochs+1,5))\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "wandb.log({'model_performance': wandb.Image(fig)})\n",
    "\n",
    "####################\n",
    "# generating CAMs #\n",
    "\n",
    "#change batch size to 1 to grab one image at a time\n",
    "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, \n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "# Load best model to produce CAMs with\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "# Save 10 palsa images\n",
    "palsa_imgs = 0\n",
    "for palsa_cam in range(100):\n",
    "    im, lab = next(iter(valid_loader))\n",
    "\n",
    "    #get the last convolution\n",
    "    sf = SaveFeatures(model.features[-4])\n",
    "    model.eval()\n",
    "\n",
    "    if lab == 1:\n",
    "        palsa_imgs+= 1\n",
    "        im = Variable(im).to(device)\n",
    "        outputs = model(im).to(device)\n",
    "        res = torch.argmax(outputs.data).cpu().detach().numpy()\n",
    "\n",
    "        # generate CAM\n",
    "        sf.remove()\n",
    "        arr = sf.features.cpu().detach().numpy()\n",
    "        arr1 = arr[0]\n",
    "        ans_nopalsa = np.dot(np.rollaxis(arr1,0,3), [1,0])\n",
    "        ans_palsa = np.dot(np.rollaxis(arr1,0,3), [0,1])\n",
    "\n",
    "        if res==1:\n",
    "            CAM = resize(ans_palsa, (im_size*2,im_size*2))\n",
    "        else:\n",
    "            CAM = resize(ans_nopalsa, (im_size*2,im_size*2))\n",
    "\n",
    "        # Plot image with CAM\n",
    "        cpu_img = im.squeeze().cpu().detach().permute(1,2,0).long().numpy()\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,7))\n",
    "\n",
    "        ax1.imshow(cpu_img)\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        ax1.set_title(f'original image')\n",
    "\n",
    "        ax2.imshow(cpu_img)\n",
    "        ax2.imshow(CAM, alpha=.4, cmap='jet')\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        ax2.set_title('image with CAM')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        wandb.log({'generated_CAM': fig})\n",
    "\n",
    "    if palsa_imgs == 20:\n",
    "        break\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "del images\n",
    "del labels\n",
    "del outputs\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# Hyperparameters #\n",
    "\n",
    "n_samples = 10000\n",
    "n_samples_train = int(round(n_samples*0.8))\n",
    "n_samples_val = int(round(n_samples*0.2))\n",
    "batch_size = 20\n",
    "current_computer =  \"ubuntu\" # \"macbook\" \n",
    "layers_to_freeze = 0\n",
    "lr = 0.00001\n",
    "weight_decay=0.02\n",
    "num_epochs = 15\n",
    "im_size = 200\n",
    "min_palsa_positive_samples = 10\n",
    "\n",
    "\n",
    "##########################\n",
    "# log hyperparams to w&b #\n",
    "\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"VGG_CAMs\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"epochs\": num_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"n_samples\": n_samples,\n",
    "        \"layers_to_freeze\": layers_to_freeze,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"im_size\": im_size,\n",
    "        \"min_palsa_positive_samples\": min_palsa_positive_samples\n",
    "    },\n",
    "    tags=['4D', 'LRScheduler', 'MSELoss', 'TrainFromScratch']\n",
    ")\n",
    "\n",
    "#############\n",
    "# Load data #\n",
    "\n",
    "if current_computer == \"ubuntu\":\n",
    "    hs_dir = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/hs'\n",
    "    RGB_dir = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/rgb'\n",
    "    labels_file = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/palsa_labels.csv'\n",
    "elif current_computer == \"macbook\":\n",
    "    hs_dir = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/hs'\n",
    "    RGB_dir = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/rgb'\n",
    "    labels_file = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/palsa_labels.csv'\n",
    "\n",
    "# Load the labels from the CSV file\n",
    "if min_palsa_positive_samples > 0:\n",
    "    labels_df = pd.read_csv(labels_file, index_col=0)\n",
    "    drop_range = labels_df[ (labels_df['palsa_percentage'] > 0) & (labels_df['palsa_percentage'] < min_palsa_positive_samples) ].index\n",
    "\n",
    "    labels_df.drop(drop_range, inplace=True)\n",
    "    labels_df = labels_df.head(n_samples)\n",
    "else: \n",
    "    labels_df = pd.read_csv(labels_file, index_col=0).head(n_samples)\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df = labels_df.head(n_samples_train)\n",
    "val_df = labels_df.drop(train_df.index)\n",
    "\n",
    "# Create the datasets and data loaders\n",
    "train_dataset = ImageDataset(hs_dir, RGB_dir, train_df, im_size)\n",
    "val_dataset = ImageDataset(hs_dir, RGB_dir, val_df, im_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = model_4D()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.92)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "##################\n",
    "# Training loop #\n",
    "\n",
    "# adapted from https://github.com/tony-mtz/CAM/blob/master/network/net.py\n",
    "\n",
    "mean_train_losses = []\n",
    "mean_val_losses = []\n",
    "\n",
    "mean_train_acc = []\n",
    "mean_val_acc = []\n",
    "\n",
    "max_val_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('EPOCH: ',epoch+1)\n",
    "\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    train_batch_count = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):     \n",
    "\n",
    "        # load images and labels \n",
    "        images = Variable(images).to(device)  \n",
    "        labels = Variable(labels.long()).to(device)  \n",
    "\n",
    "        # train batch   \n",
    "        outputs = model(images) \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "\n",
    "        # calculate loss and accuracy\n",
    "        train_acc.append(accuracy(outputs, labels.long()))\n",
    "        running_loss += loss.item()\n",
    "        train_batch_count += 1\n",
    "\n",
    "    del images\n",
    "    del labels\n",
    "    del outputs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()\n",
    "    val_batch_count = 0\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(val_loader):     \n",
    "            # load images and labels \n",
    "            images = Variable(images).to(device)  \n",
    "            labels = Variable(labels.long()).to(device)  \n",
    "            outputs = model(images) \n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            val_acc.append(accuracy(outputs, labels))\n",
    "            val_running_loss += loss.item()\n",
    "            val_batch_count +=1\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    del images\n",
    "    del labels\n",
    "    del outputs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # update losses and accuracies \n",
    "\n",
    "    mean_train_acc.append(np.mean(train_acc))\n",
    "    mean_val_acc.append(np.mean(val_acc))\n",
    "    mean_train_losses.append(running_loss/train_batch_count)\n",
    "    mean_val_losses.append(val_running_loss/val_batch_count)\n",
    "\n",
    "    wandb.log({\"train_accuracy\": np.mean(train_acc)})\n",
    "    wandb.log({\"val_accuracy\": np.mean(val_acc)})\n",
    "    wandb.log({\"train_loss\": running_loss/train_batch_count})\n",
    "    wandb.log({\"val_loss\": val_running_loss/val_batch_count})\n",
    "\n",
    "    if np.mean(val_acc) > max_val_acc:\n",
    "        best_model = model.state_dict()\n",
    "        max_val_acc = np.mean(val_acc)\n",
    "\n",
    "\n",
    "torch.save(best_model, '/home/nadjaflechner/models/model.pth')\n",
    "artifact = wandb.Artifact('model', type='model')\n",
    "artifact.add_file('/home/nadjaflechner/models/model.pth')\n",
    "run.log_artifact(artifact)\n",
    "\n",
    "##########################\n",
    "# plot loss and accuracy #\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,5))\n",
    "\n",
    "ax1.plot([i for i in range(num_epochs)], mean_val_losses, c = 'b', label = 'val loss')\n",
    "ax1.plot([i for i in range(num_epochs)], mean_train_losses, c = 'r', label = 'train loss')\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_xticks(range(0,num_epochs+1,5))\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot([i for i in range(num_epochs)], mean_val_acc, c = 'b', label = 'val accuracy')\n",
    "ax2.plot([i for i in range(num_epochs)], mean_train_acc, c = 'r', label = 'train accuracy')\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_xticks(range(0,num_epochs+1,5))\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "wandb.log({'model_performance': wandb.Image(fig)})\n",
    "\n",
    "####################\n",
    "# generating CAMs #\n",
    "\n",
    "#change batch size to 1 to grab one image at a time\n",
    "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, \n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "# Load best model to produce CAMs with\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "# Save 10 palsa images\n",
    "palsa_imgs = 0\n",
    "for palsa_cam in range(100):\n",
    "    im, lab = next(iter(valid_loader))\n",
    "\n",
    "    #get the last convolution\n",
    "    sf = SaveFeatures(model.features[-4])\n",
    "    model.eval()\n",
    "\n",
    "    if lab == 1:\n",
    "        palsa_imgs+= 1\n",
    "        im = Variable(im).to(device)\n",
    "        outputs = model(im).to(device)\n",
    "        res = torch.argmax(outputs.data).cpu().detach().numpy()\n",
    "\n",
    "        # generate CAM\n",
    "        sf.remove()\n",
    "        arr = sf.features.cpu().detach().numpy()\n",
    "        arr1 = arr[0]\n",
    "        ans_nopalsa = np.dot(np.rollaxis(arr1,0,3), [1,0])\n",
    "        ans_palsa = np.dot(np.rollaxis(arr1,0,3), [0,1])\n",
    "\n",
    "        if res==1:\n",
    "            CAM = resize(ans_palsa, (im_size*2,im_size*2))\n",
    "        else:\n",
    "            CAM = resize(ans_nopalsa, (im_size*2,im_size*2))\n",
    "\n",
    "        # Plot image with CAM\n",
    "        cpu_img = im.squeeze().cpu().detach().permute(1,2,0).long().numpy()\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,7))\n",
    "\n",
    "        ax1.imshow(cpu_img)\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        ax1.set_title(f'original image')\n",
    "\n",
    "        ax2.imshow(cpu_img)\n",
    "        ax2.imshow(CAM, alpha=.4, cmap='jet')\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        ax2.set_title('image with CAM')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        wandb.log({'generated_CAM': fig})\n",
    "\n",
    "    if palsa_imgs == 20:\n",
    "        break\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "del images\n",
    "del labels\n",
    "del outputs\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# Hyperparameters #\n",
    "\n",
    "n_samples = 10000\n",
    "n_samples_train = int(round(n_samples*0.8))\n",
    "n_samples_val = int(round(n_samples*0.2))\n",
    "batch_size = 20\n",
    "current_computer =  \"ubuntu\" # \"macbook\" \n",
    "layers_to_freeze = 0\n",
    "lr = 0.0001\n",
    "weight_decay=0.06\n",
    "num_epochs = 15\n",
    "im_size = 200\n",
    "min_palsa_positive_samples = 10\n",
    "\n",
    "\n",
    "##########################\n",
    "# log hyperparams to w&b #\n",
    "\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"VGG_CAMs\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"epochs\": num_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"n_samples\": n_samples,\n",
    "        \"layers_to_freeze\": layers_to_freeze,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"im_size\": im_size,\n",
    "        \"min_palsa_positive_samples\": min_palsa_positive_samples\n",
    "    },\n",
    "    tags=['4D', 'LRScheduler', 'MSELoss', 'TrainFromScratch']\n",
    ")\n",
    "\n",
    "#############\n",
    "# Load data #\n",
    "\n",
    "if current_computer == \"ubuntu\":\n",
    "    hs_dir = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/hs'\n",
    "    RGB_dir = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/rgb'\n",
    "    labels_file = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/palsa_labels.csv'\n",
    "elif current_computer == \"macbook\":\n",
    "    hs_dir = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/hs'\n",
    "    RGB_dir = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/rgb'\n",
    "    labels_file = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/palsa_labels.csv'\n",
    "\n",
    "# Load the labels from the CSV file\n",
    "if min_palsa_positive_samples > 0:\n",
    "    labels_df = pd.read_csv(labels_file, index_col=0)\n",
    "    drop_range = labels_df[ (labels_df['palsa_percentage'] > 0) & (labels_df['palsa_percentage'] < min_palsa_positive_samples) ].index\n",
    "\n",
    "    labels_df.drop(drop_range, inplace=True)\n",
    "    labels_df = labels_df.head(n_samples)\n",
    "else: \n",
    "    labels_df = pd.read_csv(labels_file, index_col=0).head(n_samples)\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df = labels_df.head(n_samples_train)\n",
    "val_df = labels_df.drop(train_df.index)\n",
    "\n",
    "# Create the datasets and data loaders\n",
    "train_dataset = ImageDataset(hs_dir, RGB_dir, train_df, im_size)\n",
    "val_dataset = ImageDataset(hs_dir, RGB_dir, val_df, im_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = model_4D()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.92)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "##################\n",
    "# Training loop #\n",
    "\n",
    "# adapted from https://github.com/tony-mtz/CAM/blob/master/network/net.py\n",
    "\n",
    "mean_train_losses = []\n",
    "mean_val_losses = []\n",
    "\n",
    "mean_train_acc = []\n",
    "mean_val_acc = []\n",
    "\n",
    "max_val_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('EPOCH: ',epoch+1)\n",
    "\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    train_batch_count = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):     \n",
    "\n",
    "        # load images and labels \n",
    "        images = Variable(images).to(device)  \n",
    "        labels = Variable(labels.long()).to(device)  \n",
    "\n",
    "        # train batch   \n",
    "        outputs = model(images) \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "\n",
    "        # calculate loss and accuracy\n",
    "        train_acc.append(accuracy(outputs, labels.long()))\n",
    "        running_loss += loss.item()\n",
    "        train_batch_count += 1\n",
    "\n",
    "    del images\n",
    "    del labels\n",
    "    del outputs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()\n",
    "    val_batch_count = 0\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(val_loader):     \n",
    "            # load images and labels \n",
    "            images = Variable(images).to(device)  \n",
    "            labels = Variable(labels.long()).to(device)  \n",
    "            outputs = model(images) \n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            val_acc.append(accuracy(outputs, labels))\n",
    "            val_running_loss += loss.item()\n",
    "            val_batch_count +=1\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    del images\n",
    "    del labels\n",
    "    del outputs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # update losses and accuracies \n",
    "\n",
    "    mean_train_acc.append(np.mean(train_acc))\n",
    "    mean_val_acc.append(np.mean(val_acc))\n",
    "    mean_train_losses.append(running_loss/train_batch_count)\n",
    "    mean_val_losses.append(val_running_loss/val_batch_count)\n",
    "\n",
    "    wandb.log({\"train_accuracy\": np.mean(train_acc)})\n",
    "    wandb.log({\"val_accuracy\": np.mean(val_acc)})\n",
    "    wandb.log({\"train_loss\": running_loss/train_batch_count})\n",
    "    wandb.log({\"val_loss\": val_running_loss/val_batch_count})\n",
    "\n",
    "    if np.mean(val_acc) > max_val_acc:\n",
    "        best_model = model.state_dict()\n",
    "        max_val_acc = np.mean(val_acc)\n",
    "\n",
    "\n",
    "torch.save(best_model, '/home/nadjaflechner/models/model.pth')\n",
    "artifact = wandb.Artifact('model', type='model')\n",
    "artifact.add_file('/home/nadjaflechner/models/model.pth')\n",
    "run.log_artifact(artifact)\n",
    "\n",
    "##########################\n",
    "# plot loss and accuracy #\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,5))\n",
    "\n",
    "ax1.plot([i for i in range(num_epochs)], mean_val_losses, c = 'b', label = 'val loss')\n",
    "ax1.plot([i for i in range(num_epochs)], mean_train_losses, c = 'r', label = 'train loss')\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_xticks(range(0,num_epochs+1,5))\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot([i for i in range(num_epochs)], mean_val_acc, c = 'b', label = 'val accuracy')\n",
    "ax2.plot([i for i in range(num_epochs)], mean_train_acc, c = 'r', label = 'train accuracy')\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_xticks(range(0,num_epochs+1,5))\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "wandb.log({'model_performance': wandb.Image(fig)})\n",
    "\n",
    "####################\n",
    "# generating CAMs #\n",
    "\n",
    "#change batch size to 1 to grab one image at a time\n",
    "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, \n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "# Load best model to produce CAMs with\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "# Save 10 palsa images\n",
    "palsa_imgs = 0\n",
    "for palsa_cam in range(100):\n",
    "    im, lab = next(iter(valid_loader))\n",
    "\n",
    "    #get the last convolution\n",
    "    sf = SaveFeatures(model.features[-4])\n",
    "    model.eval()\n",
    "\n",
    "    if lab == 1:\n",
    "        palsa_imgs+= 1\n",
    "        im = Variable(im).to(device)\n",
    "        outputs = model(im).to(device)\n",
    "        res = torch.argmax(outputs.data).cpu().detach().numpy()\n",
    "\n",
    "        # generate CAM\n",
    "        sf.remove()\n",
    "        arr = sf.features.cpu().detach().numpy()\n",
    "        arr1 = arr[0]\n",
    "        ans_nopalsa = np.dot(np.rollaxis(arr1,0,3), [1,0])\n",
    "        ans_palsa = np.dot(np.rollaxis(arr1,0,3), [0,1])\n",
    "\n",
    "        if res==1:\n",
    "            CAM = resize(ans_palsa, (im_size*2,im_size*2))\n",
    "        else:\n",
    "            CAM = resize(ans_nopalsa, (im_size*2,im_size*2))\n",
    "\n",
    "        # Plot image with CAM\n",
    "        cpu_img = im.squeeze().cpu().detach().permute(1,2,0).long().numpy()\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,7))\n",
    "\n",
    "        ax1.imshow(cpu_img)\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        ax1.set_title(f'original image')\n",
    "\n",
    "        ax2.imshow(cpu_img)\n",
    "        ax2.imshow(CAM, alpha=.4, cmap='jet')\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        ax2.set_title('image with CAM')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        wandb.log({'generated_CAM': fig})\n",
    "\n",
    "    if palsa_imgs == 20:\n",
    "        break\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "del images\n",
    "del labels\n",
    "del outputs\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# Hyperparameters #\n",
    "\n",
    "n_samples = 10000\n",
    "n_samples_train = int(round(n_samples*0.8))\n",
    "n_samples_val = int(round(n_samples*0.2))\n",
    "batch_size = 20\n",
    "current_computer =  \"ubuntu\" # \"macbook\" \n",
    "layers_to_freeze = 0\n",
    "lr = 0.00001\n",
    "weight_decay=0.04\n",
    "num_epochs = 10\n",
    "im_size = 200\n",
    "min_palsa_positive_samples = 10\n",
    "\n",
    "\n",
    "##########################\n",
    "# log hyperparams to w&b #\n",
    "\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"VGG_CAMs\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"epochs\": num_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"n_samples\": n_samples,\n",
    "        \"layers_to_freeze\": layers_to_freeze,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"im_size\": im_size,\n",
    "        \"min_palsa_positive_samples\": min_palsa_positive_samples\n",
    "    },\n",
    "    tags=['4D', 'LRScheduler', 'MSELoss', 'TrainFromScratch']\n",
    ")\n",
    "\n",
    "#############\n",
    "# Load data #\n",
    "\n",
    "if current_computer == \"ubuntu\":\n",
    "    hs_dir = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/hs'\n",
    "    RGB_dir = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/rgb'\n",
    "    labels_file = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/palsa_labels.csv'\n",
    "elif current_computer == \"macbook\":\n",
    "    hs_dir = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/hs'\n",
    "    RGB_dir = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/rgb'\n",
    "    labels_file = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/palsa_labels.csv'\n",
    "\n",
    "# Load the labels from the CSV file\n",
    "if min_palsa_positive_samples > 0:\n",
    "    labels_df = pd.read_csv(labels_file, index_col=0)\n",
    "    drop_range = labels_df[ (labels_df['palsa_percentage'] > 0) & (labels_df['palsa_percentage'] < min_palsa_positive_samples) ].index\n",
    "\n",
    "    labels_df.drop(drop_range, inplace=True)\n",
    "    labels_df = labels_df.head(n_samples)\n",
    "else: \n",
    "    labels_df = pd.read_csv(labels_file, index_col=0).head(n_samples)\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df = labels_df.head(n_samples_train)\n",
    "val_df = labels_df.drop(train_df.index)\n",
    "\n",
    "# Create the datasets and data loaders\n",
    "train_dataset = ImageDataset(hs_dir, RGB_dir, train_df, im_size)\n",
    "val_dataset = ImageDataset(hs_dir, RGB_dir, val_df, im_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = model_4D()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.92)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "##################\n",
    "# Training loop #\n",
    "\n",
    "# adapted from https://github.com/tony-mtz/CAM/blob/master/network/net.py\n",
    "\n",
    "mean_train_losses = []\n",
    "mean_val_losses = []\n",
    "\n",
    "mean_train_acc = []\n",
    "mean_val_acc = []\n",
    "\n",
    "max_val_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('EPOCH: ',epoch+1)\n",
    "\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    train_batch_count = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):     \n",
    "\n",
    "        # load images and labels \n",
    "        images = Variable(images).to(device)  \n",
    "        labels = Variable(labels.long()).to(device)  \n",
    "\n",
    "        # train batch   \n",
    "        outputs = model(images) \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "\n",
    "        # calculate loss and accuracy\n",
    "        train_acc.append(accuracy(outputs, labels.long()))\n",
    "        running_loss += loss.item()\n",
    "        train_batch_count += 1\n",
    "\n",
    "    del images\n",
    "    del labels\n",
    "    del outputs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()\n",
    "    val_batch_count = 0\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(val_loader):     \n",
    "            # load images and labels \n",
    "            images = Variable(images).to(device)  \n",
    "            labels = Variable(labels.long()).to(device)  \n",
    "            outputs = model(images) \n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            val_acc.append(accuracy(outputs, labels))\n",
    "            val_running_loss += loss.item()\n",
    "            val_batch_count +=1\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    del images\n",
    "    del labels\n",
    "    del outputs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # update losses and accuracies \n",
    "\n",
    "    mean_train_acc.append(np.mean(train_acc))\n",
    "    mean_val_acc.append(np.mean(val_acc))\n",
    "    mean_train_losses.append(running_loss/train_batch_count)\n",
    "    mean_val_losses.append(val_running_loss/val_batch_count)\n",
    "\n",
    "    wandb.log({\"train_accuracy\": np.mean(train_acc)})\n",
    "    wandb.log({\"val_accuracy\": np.mean(val_acc)})\n",
    "    wandb.log({\"train_loss\": running_loss/train_batch_count})\n",
    "    wandb.log({\"val_loss\": val_running_loss/val_batch_count})\n",
    "\n",
    "    if np.mean(val_acc) > max_val_acc:\n",
    "        best_model = model.state_dict()\n",
    "        max_val_acc = np.mean(val_acc)\n",
    "\n",
    "\n",
    "torch.save(best_model, '/home/nadjaflechner/models/model.pth')\n",
    "artifact = wandb.Artifact('model', type='model')\n",
    "artifact.add_file('/home/nadjaflechner/models/model.pth')\n",
    "run.log_artifact(artifact)\n",
    "\n",
    "##########################\n",
    "# plot loss and accuracy #\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,5))\n",
    "\n",
    "ax1.plot([i for i in range(num_epochs)], mean_val_losses, c = 'b', label = 'val loss')\n",
    "ax1.plot([i for i in range(num_epochs)], mean_train_losses, c = 'r', label = 'train loss')\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_xticks(range(0,num_epochs+1,5))\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot([i for i in range(num_epochs)], mean_val_acc, c = 'b', label = 'val accuracy')\n",
    "ax2.plot([i for i in range(num_epochs)], mean_train_acc, c = 'r', label = 'train accuracy')\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_xticks(range(0,num_epochs+1,5))\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "wandb.log({'model_performance': wandb.Image(fig)})\n",
    "\n",
    "####################\n",
    "# generating CAMs #\n",
    "\n",
    "#change batch size to 1 to grab one image at a time\n",
    "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, \n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "# Load best model to produce CAMs with\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "# Save 10 palsa images\n",
    "palsa_imgs = 0\n",
    "for palsa_cam in range(100):\n",
    "    im, lab = next(iter(valid_loader))\n",
    "\n",
    "    #get the last convolution\n",
    "    sf = SaveFeatures(model.features[-4])\n",
    "    model.eval()\n",
    "\n",
    "    if lab == 1:\n",
    "        palsa_imgs+= 1\n",
    "        im = Variable(im).to(device)\n",
    "        outputs = model(im).to(device)\n",
    "        res = torch.argmax(outputs.data).cpu().detach().numpy()\n",
    "\n",
    "        # generate CAM\n",
    "        sf.remove()\n",
    "        arr = sf.features.cpu().detach().numpy()\n",
    "        arr1 = arr[0]\n",
    "        ans_nopalsa = np.dot(np.rollaxis(arr1,0,3), [1,0])\n",
    "        ans_palsa = np.dot(np.rollaxis(arr1,0,3), [0,1])\n",
    "\n",
    "        if res==1:\n",
    "            CAM = resize(ans_palsa, (im_size*2,im_size*2))\n",
    "        else:\n",
    "            CAM = resize(ans_nopalsa, (im_size*2,im_size*2))\n",
    "\n",
    "        # Plot image with CAM\n",
    "        cpu_img = im.squeeze().cpu().detach().permute(1,2,0).long().numpy()\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,7))\n",
    "\n",
    "        ax1.imshow(cpu_img)\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        ax1.set_title(f'original image')\n",
    "\n",
    "        ax2.imshow(cpu_img)\n",
    "        ax2.imshow(CAM, alpha=.4, cmap='jet')\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        ax2.set_title('image with CAM')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        wandb.log({'generated_CAM': fig})\n",
    "\n",
    "    if palsa_imgs == 20:\n",
    "        break\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "del images\n",
    "del labels\n",
    "del outputs\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
