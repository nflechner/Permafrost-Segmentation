{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics import Accuracy\n",
    "from utils import ImageDataset, SaveFeatures, imshow_transform\n",
    "from custom_model import model_4D\n",
    "from torch.autograd import Variable\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imshow\n",
    "import wandb\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_computer =  \"ubuntu\" # \"macbook\" \n",
    "im_size = 200\n",
    "\n",
    "\n",
    "if current_computer == \"ubuntu\":\n",
    "    hs_dir = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/hs'\n",
    "    RGB_dir = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/rgb'\n",
    "    labels_file = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/palsa_labels.csv'\n",
    "elif current_computer == \"macbook\":\n",
    "    hs_dir = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/hs'\n",
    "    RGB_dir = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/rgb'\n",
    "    labels_file = '/Users/nadja/Documents/UU/Thesis/Data/cropped_hillshade/palsa_labels.csv'\n",
    "\n",
    "labels_df = pd.read_csv(labels_file, index_col=0)\n",
    "testing_dataset =  ImageDataset(hs_dir, RGB_dir, labels_df, im_size)\n",
    "test_loader = DataLoader(testing_dataset, batch_size=1, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "run = wandb.init(project= 'VGG_CAMs', id= 'v6ax9crk', resume = 'must')\n",
    "artifact = run.use_artifact('nadjaflechner/VGG_CAMs/model:v9', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "state_dict = torch.load(f\"{artifact_dir}/model.pth\")\n",
    "model = model_4D()\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab an image label pair to \n",
    "im, lab = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# generating CAM #\n",
    "###################\n",
    "\n",
    "#get the last convolution\n",
    "sf = SaveFeatures(model.features[-4])\n",
    "\n",
    "if lab == 1:\n",
    "    palsa_imgs+= 1\n",
    "    im = Variable(im).to(device)\n",
    "    outputs = model(im).to(device)\n",
    "    res = torch.argmax(outputs.data).cpu().detach().numpy()\n",
    "\n",
    "    # generate CAM\n",
    "    sf.remove()\n",
    "    arr = sf.features.cpu().detach().numpy()\n",
    "    arr1 = arr[0]\n",
    "    ans_nopalsa = np.dot(np.rollaxis(arr1,0,3), [1,0])\n",
    "    ans_palsa = np.dot(np.rollaxis(arr1,0,3), [0,1])\n",
    "\n",
    "    if res==1:\n",
    "        CAM = resize(ans_palsa, (im_size*2,im_size*2))\n",
    "    else:\n",
    "        CAM = resize(ans_nopalsa, (im_size*2,im_size*2))\n",
    "\n",
    "    # Plot image with CAM\n",
    "    cpu_img = im.squeeze().cpu().detach().permute(1,2,0).long().numpy()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,7))\n",
    "\n",
    "    ax1.imshow(cpu_img)\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_title(f'original image')\n",
    "\n",
    "    ax2.imshow(cpu_img)\n",
    "    ax2.imshow(CAM, alpha=.4, cmap='jet')\n",
    "    ax2.set_xticks([])\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_title('image with CAM')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
