{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do list for implementation from scratch\n",
    "\n",
    "*Resources*\n",
    "\n",
    "* https://brsoff.github.io/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "* https://rumn.medium.com/part-1-ultimate-guide-to-fine-tuning-in-pytorch-pre-trained-model-and-its-configuration-8990194b71e\n",
    "* https://pytorch.org/vision/stable/models/generated/torchvision.models.vgg16.html#torchvision.models.vgg16\n",
    "\n",
    "*Stappenplan*\n",
    "* Look at details of how SMILIES implemented VGG.\n",
    "* Prepare and transform data (according to needs of pretrained model)\n",
    "* Look into what pytorch calls 'feature extraction' (only changing classification head), not 'fine tuning' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pretrained VGG \"Accepts PIL.Image, batched (B, C, H, W) and single (C, H, W) image torch.Tensor objects\"\n",
    "\n",
    "* must convert the TIF into a format that it can be read by PIL, or use single Tensor objects\n",
    "* But if using batch i assume PIL must be used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels_df):\n",
    "        self.image_dir = image_dir\n",
    "        self.labels_df = labels_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.labels_df.index[idx]\n",
    "        label = self.labels_df.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.image_dir, f\"{img_name}.tif\")\n",
    "\n",
    "        # Open image as PIL (required by pretrained VGG)\n",
    "        with Image.open(img_path) as im:\n",
    "            PIL_img = im\n",
    "        \n",
    "        return PIL_img, label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.TiffImagePlugin.TiffImageFile'>\n"
     ]
    }
   ],
   "source": [
    "with Image.open(\"/home/nadjaflechner/Palsa_data/dataset_100m/760_77_50_2016_neg_crop_0.tif\") as im:\n",
    "    print(type(im))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_dir = \"/home/nadjaflechner/Palsa_data/dataset_100m/\"\n",
    "labels_file = \"/home/nadjaflechner/Palsa_data/binary_palsa_labels_100m.csv\"\n",
    "\n",
    "# Load the labels from the CSV file\n",
    "labels_df = pd.read_csv(labels_file, index_col=0).head(5000)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df = labels_df.head(4000)\n",
    "val_df = labels_df.drop(train_df.index)\n",
    "\n",
    "# Create the datasets and data loaders\n",
    "train_dataset = ImageDataset(image_dir, train_df )\n",
    "val_dataset = ImageDataset(image_dir, val_df )\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_only_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
