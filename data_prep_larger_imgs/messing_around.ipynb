{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np \n",
    "import pandas\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "import os\n",
    "import json\n",
    "from shapely.geometry import box, Polygon\n",
    "import logging\n",
    "\n",
    "class Crop_tif_varsize():\n",
    "    \"\"\"\n",
    "    In: tif image to be cropped, and whole extent of 100x100 rutor\n",
    "    Returns: directory of one cropped tif per 100x100 ruta.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_name_code, img_path, rutor_path, destination_path, dims, logger):\n",
    "\n",
    "        self.img_name_code = img_name_code\n",
    "        self.dimensions = dims\n",
    "        print(self.dimensions)\n",
    "        self.destination_path = destination_path\n",
    "        self.logger = logger\n",
    "        self.img_path = img_path\n",
    "        self.rutor_path = rutor_path\n",
    "\n",
    "        self.img = rasterio.open(img_path)\n",
    "        self.rutor = gpd.read_file(rutor_path)\n",
    "        self.filtered_rutor = self.filter_rutor()\n",
    "        self.img_rutor = self.reshape_rutor() # this will at some point have as input the filtered rutor. \n",
    "\n",
    "    def filter_rutor(self):\n",
    "        # Find which 100x100 squares overlap with the current TIF\n",
    "\n",
    "        minx, miny, maxx, maxy = self.img.bounds\n",
    "        img_rutor = self.rutor.cx[minx:maxx, miny:maxy] # coordinates derived manually from plotting img\n",
    "        return img_rutor\n",
    "    \n",
    "    def reshape_rutor(self):\n",
    "        # Reshape rutor according to dims \n",
    "\n",
    "        new_dim_rutor = self.generate_geoseries(self.img.bounds, self.img.crs, self.dimensions)\n",
    "        return new_dim_rutor\n",
    "\n",
    "\n",
    "    def crop_rutor(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Crop TIF according to the polygons containing palsa. \n",
    "        \"\"\"\n",
    "\n",
    "        cropped_tifs_percentages = {}\n",
    "        # Iterate over each polygon in the GeoDataFrame\n",
    "        for idx, percentage, polygon in zip(self.img_rutor.index, self.img_rutor.PALS, self.img_rutor.geometry):\n",
    "            # Crop the TIF file using the polygon\n",
    "            cropped_data, cropped_transform = mask(self.img, [polygon], crop=True)\n",
    "\n",
    "            # Update the metadata for the cropped TIF\n",
    "            cropped_meta = self.img.meta.copy()\n",
    "            cropped_meta.update({\"driver\": \"GTiff\",\n",
    "                                \"height\": cropped_data.shape[1],\n",
    "                                \"width\": cropped_data.shape[2],\n",
    "                                \"transform\": cropped_transform})\n",
    "\n",
    "            # Save the cropped TIF file with a unique name\n",
    "            output_path = os.path.join(self.destination_path, f\"{self.img_name_code}_crop_{idx}.tif\") # CHANGE THIS NAMING? \n",
    "            with rasterio.open(output_path, \"w\", **cropped_meta) as dest:\n",
    "                dest.write(cropped_data)\n",
    "\n",
    "            # Write the corresponding percentage to a dictionary as label \n",
    "            cropped_tifs_percentages[f\"{self.img_name_code}_crop_{idx}\"] = percentage\n",
    "\n",
    "        return cropped_tifs_percentages\n",
    "    \n",
    "    def generate_geoseries(self, bounds, crs, dims):\n",
    "\n",
    "        \"\"\"\n",
    "        Generates all 100x100m polygons present in a TIF.\n",
    "        Enables the negative sampling from the image. \n",
    "        \"\"\"\n",
    "\n",
    "        # height and width of new squares \n",
    "        square_dims = dims # 100x100 meters\n",
    "\n",
    "        # Calculate the number of segments in each dimension (tif width // desired width in pixels!)\n",
    "        segments_x = 5000 // square_dims\n",
    "        segments_y = 5000 // square_dims\n",
    "\n",
    "        # Create an empty list to store the polygons\n",
    "        polygons = []\n",
    "\n",
    "        # Iterate over the segments\n",
    "        for i in range(segments_y):\n",
    "            for j in range(segments_x):\n",
    "                # Calculate the coordinates of the segment\n",
    "                left = bounds.left + j * square_dims\n",
    "                bottom = bounds.bottom + i * square_dims\n",
    "                right = left + square_dims\n",
    "                top = bottom + square_dims\n",
    "\n",
    "                # Create a polygon for the segment\n",
    "                polygon = Polygon([(right, bottom), (left, bottom), (left, top), (right, top), (right, bottom)])\n",
    "\n",
    "                # Append the polygon to the list\n",
    "                polygons.append(polygon)\n",
    "\n",
    "        # Create a GeoSeries from the list of polygons\n",
    "        all_rutor = gpd.GeoSeries(polygons, crs=crs)\n",
    "        return all_rutor\n",
    "\n",
    "    def crop_negatives(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Generates negative samples. Equal amount of negative as positive samples are\n",
    "        taken from each image such that the final dataset is 50/50 positive and negative. \n",
    "\n",
    "            1) split the whole TIF into 100x100m polygons.\n",
    "            2) filter out the areas containing palsa (positive samples)\n",
    "            3) randomly sample as many negative samples as positive samples from that image\n",
    "            4) crop the TIF according to the sampled areas and write locally\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # generate polygon for all 100x100m patches in the tif\n",
    "        all_rutor = self.generate_geoseries(self.img.bounds, self.img.crs, dims = 100)\n",
    "\n",
    "        # filter out the squares with palsa \n",
    "        positives_mask = ~all_rutor.isin(self.img_rutor.geometry)\n",
    "        all_negatives = all_rutor[positives_mask]\n",
    "\n",
    "        # randomly sample \n",
    "        sample_size = int(len(self.img_rutor)) # based on number of positive samples \n",
    "        if sample_size <= len(all_negatives): # default case\n",
    "            negative_samples = all_negatives.sample(n=sample_size) # sample randomly\n",
    "        else:\n",
    "            self.logger.info('Exception occurred! Number of positive samples > 1/2 image. Training set now contains fewer negative than positive samples.')\n",
    "            negative_samples = all_negatives\n",
    "\n",
    "        cropped_tifs_percentages = {}\n",
    "        # Iterate over each polygon in the GeoDataFrame\n",
    "        for idx, polygon in enumerate(negative_samples.geometry):\n",
    "            # Crop the TIF file using the polygon\n",
    "            cropped_data, cropped_transform = mask(self.img, [polygon], crop=True)\n",
    "\n",
    "            # Update the metadata for the cropped TIF\n",
    "            cropped_meta = self.img.meta.copy()\n",
    "            cropped_meta.update({\"driver\": \"GTiff\",\n",
    "                                \"height\": cropped_data.shape[1],\n",
    "                                \"width\": cropped_data.shape[2],\n",
    "                                \"transform\": cropped_transform})\n",
    "\n",
    "            # Save the cropped TIF file with a unique name\n",
    "            output_path = os.path.join(self.destination_path, f\"{self.img_name_code}_neg_crop_{idx}.tif\") # CHANGE THIS NAMING? \n",
    "            with rasterio.open(output_path, \"w\", **cropped_meta) as dest:\n",
    "                dest.write(cropped_data)\n",
    "\n",
    "            # Write the corresponding percentage to a dictionary as label \n",
    "            cropped_tifs_percentages[f\"{self.img_name_code}_neg_crop_{idx}\"] = 0\n",
    "\n",
    "        return cropped_tifs_percentages\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 <class 'int'>\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "## imports ##\n",
    "#############\n",
    "\n",
    "# libraries \n",
    "import geopandas as gpd\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# functions \n",
    "from functions import filter_imgs, Crop_tif\n",
    "\n",
    "##################\n",
    "## setup logger ##\n",
    "##################\n",
    "\n",
    "logger = logging.getLogger('my_logger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Setup logger\n",
    "ch = logging.StreamHandler() # create console handler\n",
    "ch.setLevel(logging.DEBUG) # set level to debug\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(message)s \\n\", \"%Y-%m-%d %H:%M:%S\") # create formatter\n",
    "ch.setFormatter(formatter) # add formatter to ch\n",
    "logger.addHandler(ch) # add ch to logger\n",
    "\n",
    "# logger.info('Imports successful')\n",
    "\n",
    "##################\n",
    "## load configs ##\n",
    "##################\n",
    "\n",
    "config_path = os.path.join(os.getcwd(), 'configs.json')\n",
    "with open(config_path, 'r') as config_file:\n",
    "    configs = json.load(config_file)\n",
    "\n",
    "# load paths from configs \n",
    "config_paths = configs.get('paths', {}) \n",
    "palsa_shapefile_path = config_paths.get('palsa_shapefile_path') # load shapefile path\n",
    "save_crops_dir = config_paths.get('save_crops_dir') # load directory with all tifs\n",
    "original_tif_dir = config_paths.get('original_tif_dir') # load directory with all tifs\n",
    "\n",
    "config_img = configs.get('image_info', {}) \n",
    "dims = config_img.get('meters_per_axis') # load shapefile path\n",
    "\n",
    "# logger.info('Configurations were loaded')\n",
    "\n",
    "##########\n",
    "## code ##\n",
    "##########\n",
    "\n",
    "# logger.info('Starting to sample relevant TIF paths...')\n",
    "\n",
    "# extract tif file names which contain palsa\n",
    "palsa_tifs = filter_imgs(original_tif_dir) # returns a list of filenames to be cropped\n",
    "\n",
    "# logger.info(f'{len(palsa_tifs)} TIF paths have been loaded!')\n",
    "# logger.info('Starting to generate training samples from TIFs..')\n",
    "\n",
    "labels = {}\n",
    "\n",
    "print(dims, type(dims))\n",
    "\n",
    "# load palsa shape path\n",
    "for idx, img_name in enumerate(palsa_tifs):\n",
    "    img_name_code = img_name.split('.')[0]\n",
    "    img_path = os.path.join(original_tif_dir, img_name)\n",
    "    cropping = Crop_tif(img_name_code, img_path, palsa_shapefile_path, save_crops_dir, dims, logger)\n",
    "\n",
    "    break\n",
    "\n",
    "#     positive_labels = cropping.crop_rutor()\n",
    "#     negative_labels = cropping.crop_negatives()\n",
    "#     all_labels = positive_labels | negative_labels\n",
    "#     labels = labels | all_labels\n",
    "#     # logger.info(f'Generated training samples from image {idx+1}/{len(palsa_tifs)}')\n",
    "\n",
    "# label_df = pd.DataFrame.from_dict(labels, orient='index', columns = ['palsa_percentage'])\n",
    "# label_df.to_csv(os.path.join(save_crops_dir, \"palsa_labels.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_rutor = cropping.filtered_rutor\n",
    "all_rutor = cropping.img_rutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Assuming you have all_rutor and orig_rutor loaded as GeoDataFrame objects\n",
    "d = {'name': [i for i in range(len(all_rutor))]}\n",
    "df = pd.DataFrame(d)\n",
    "all_rutor_df = gpd.GeoDataFrame(d, geometry = all_rutor, crs=all_rutor.crs)\n",
    "\n",
    "\n",
    "# Perform a spatial join between all_rutor and orig_rutor\n",
    "joined_df = gpd.sjoin(all_rutor_df, orig_rutor, how='inner')\n",
    "\n",
    "# Get the unique index values of the polygons in all_rutor_df that cover at least one smaller polygon\n",
    "covering_polygons_index = joined_df.index.unique()\n",
    "\n",
    "# Select the polygons from all_rutor_df that cover at least one smaller polygon\n",
    "result_df = all_rutor_df.loc[covering_polygons_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(joined_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(x):\n",
    "    if x == 1:\n",
    "        return 2\n",
    "    \n",
    "    print('hello')\n",
    "    return 3\n",
    "\n",
    "test(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "palsa_env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
