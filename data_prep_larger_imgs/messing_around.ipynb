{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 <class 'int'>\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "## imports ##\n",
    "#############\n",
    "\n",
    "# libraries \n",
    "import geopandas as gpd\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# functions \n",
    "from functions import filter_imgs, Crop_tif\n",
    "\n",
    "##################\n",
    "## setup logger ##\n",
    "##################\n",
    "\n",
    "logger = logging.getLogger('my_logger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Setup logger\n",
    "ch = logging.StreamHandler() # create console handler\n",
    "ch.setLevel(logging.DEBUG) # set level to debug\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(message)s \\n\", \"%Y-%m-%d %H:%M:%S\") # create formatter\n",
    "ch.setFormatter(formatter) # add formatter to ch\n",
    "logger.addHandler(ch) # add ch to logger\n",
    "\n",
    "# logger.info('Imports successful')\n",
    "\n",
    "##################\n",
    "## load configs ##\n",
    "##################\n",
    "\n",
    "config_path = os.path.join(os.getcwd(), 'configs.json')\n",
    "with open(config_path, 'r') as config_file:\n",
    "    configs = json.load(config_file)\n",
    "\n",
    "# load paths from configs \n",
    "config_paths = configs.get('paths', {}) \n",
    "palsa_shapefile_path = config_paths.get('palsa_shapefile_path') # load shapefile path\n",
    "save_crops_dir = config_paths.get('save_crops_dir') # load directory with all tifs\n",
    "original_tif_dir = config_paths.get('original_tif_dir') # load directory with all tifs\n",
    "\n",
    "config_img = configs.get('image_info', {}) \n",
    "dims = config_img.get('meters_per_axis') # load shapefile path\n",
    "\n",
    "# logger.info('Configurations were loaded')\n",
    "\n",
    "##########\n",
    "## code ##\n",
    "##########\n",
    "\n",
    "# logger.info('Starting to sample relevant TIF paths...')\n",
    "\n",
    "# extract tif file names which contain palsa\n",
    "palsa_tifs = filter_imgs(original_tif_dir) # returns a list of filenames to be cropped\n",
    "\n",
    "# logger.info(f'{len(palsa_tifs)} TIF paths have been loaded!')\n",
    "# logger.info('Starting to generate training samples from TIFs..')\n",
    "\n",
    "labels = {}\n",
    "\n",
    "print(dims, type(dims))\n",
    "\n",
    "# load palsa shape path\n",
    "for idx, img_name in enumerate(palsa_tifs):\n",
    "    img_name_code = img_name.split('.')[0]\n",
    "    img_path = os.path.join(original_tif_dir, img_name)\n",
    "    cropping = Crop_tif(img_name_code, img_path, palsa_shapefile_path, save_crops_dir, dims, logger)\n",
    "\n",
    "    break\n",
    "\n",
    "#     positive_labels = cropping.crop_rutor()\n",
    "#     negative_labels = cropping.crop_negatives()\n",
    "#     all_labels = positive_labels | negative_labels\n",
    "#     labels = labels | all_labels\n",
    "#     # logger.info(f'Generated training samples from image {idx+1}/{len(palsa_tifs)}')\n",
    "\n",
    "# label_df = pd.DataFrame.from_dict(labels, orient='index', columns = ['palsa_percentage'])\n",
    "# label_df.to_csv(os.path.join(save_crops_dir, \"palsa_labels.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_rutor = cropping.filtered_rutor\n",
    "all_rutor = cropping.img_rutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Assuming you have all_rutor and orig_rutor loaded as GeoDataFrame objects\n",
    "d = {'name': [i for i in range(len(all_rutor))]}\n",
    "df = pd.DataFrame(d)\n",
    "all_rutor_df = gpd.GeoDataFrame(d, geometry = all_rutor, crs=all_rutor.crs)\n",
    "\n",
    "\n",
    "# Perform a spatial join between all_rutor and orig_rutor\n",
    "joined_df = gpd.sjoin(all_rutor_df, orig_rutor, how='inner')\n",
    "\n",
    "# Get the unique index values of the polygons in all_rutor_df that cover at least one smaller polygon\n",
    "covering_polygons_index = joined_df.index.unique()\n",
    "\n",
    "# Select the polygons from all_rutor_df that cover at least one smaller polygon\n",
    "result_df = all_rutor_df.loc[covering_polygons_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "palsa_env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
