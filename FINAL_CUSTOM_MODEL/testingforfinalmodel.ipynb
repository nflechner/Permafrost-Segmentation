{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTS:\n",
    "\n",
    "##### RGB \n",
    "- means = array([74.90059245, 85.25801497, 80.06076522])\n",
    "- stdevs = array([15.05452957, 13.87736375, 12.01005956])\n",
    "\n",
    "##### DEM \n",
    "- means = array([608.951834])\n",
    "- stdevs = array([2.30201424])\n",
    "\n",
    "\n",
    "##### HS \n",
    "- means = array([179.17519397])\n",
    "- stdevs = array([10.65291866])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE FOR CALCULATING DATASET-WIDE MEAN AND STD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# RGB #\n",
    "#######\n",
    "\n",
    "import os\n",
    "import rasterio \n",
    "import numpy as np\n",
    "\n",
    "dir = \"/home/nadjaflechner/Palsa_data/generated_datasets/FINAL_200m_dataset/rgb/\"\n",
    "all_rgb = os.listdir(dir)\n",
    "all_rgb = [file for file in all_rgb if not file.endswith('aug.tif')]\n",
    "\n",
    "img_means_sum = np.array([0.0,0.0,0.0])\n",
    "img_std_sum = np.array([0.0,0.0,0.0])\n",
    "\n",
    "\n",
    "for img in all_rgb:\n",
    "    with rasterio.open(os.path.join(dir, img)) as img:\n",
    "        img = img.read()\n",
    "    img_means_sum += img.mean(axis=(1,2))\n",
    "    img_std_sum += img.std(axis=(1,2))\n",
    "\n",
    "\n",
    "means = img_means_sum / len(all_rgb)\n",
    "stds = img_std_sum / len(all_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([74.90059245, 85.25801497, 80.06076522])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.05452957, 13.87736375, 12.01005956])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# dem #\n",
    "##########\n",
    "\n",
    "import os\n",
    "import rasterio \n",
    "import numpy as np\n",
    "\n",
    "dir = \"/home/nadjaflechner/Palsa_data/generated_datasets/FINAL_200m_dataset/dem/\"\n",
    "all_rgb = os.listdir(dir)\n",
    "all_rgb = [file for file in all_rgb if not file.endswith('aug.tif')]\n",
    "\n",
    "img_means_sum = np.array([0.0])\n",
    "img_std_sum = np.array([0.0])\n",
    "\n",
    "\n",
    "for img in all_rgb:\n",
    "    with rasterio.open(os.path.join(dir, img)) as img:\n",
    "        img = img.read()\n",
    "    img_means_sum += img.mean()\n",
    "    img_std_sum += img.std()\n",
    "\n",
    "dem_means = img_means_sum / len(all_rgb)\n",
    "dem_stds = img_std_sum / len(all_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.30201424])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dem_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# hs #\n",
    "##########\n",
    "\n",
    "import os\n",
    "import rasterio \n",
    "import numpy as np\n",
    "\n",
    "dir = \"/home/nadjaflechner/Palsa_data/generated_datasets/FINAL_200m_dataset/hs/\"\n",
    "all_rgb = os.listdir(dir)\n",
    "all_rgb = [file for file in all_rgb if not file.endswith('aug.tif')]\n",
    "\n",
    "img_means_sum = np.array([0.0])\n",
    "img_std_sum = np.array([0.0])\n",
    "\n",
    "\n",
    "for img in all_rgb:\n",
    "    with rasterio.open(os.path.join(dir, img)) as img:\n",
    "        img = img.read()\n",
    "    img_means_sum += img.mean()\n",
    "    img_std_sum += img.std()\n",
    "\n",
    "hs_means = img_means_sum / len(all_rgb)\n",
    "hs_stds = img_std_sum / len(all_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([179.17519397])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.65291866])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messing around: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  1\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# Imports #\n",
    "############\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from utils import ImageDataset, SaveFeatures, filter_dataset, accuracy, imshow_transform\n",
    "from custom_model import model_4D\n",
    "from torch.autograd import Variable\n",
    "# from skimage.transform import resize\n",
    "# from skimage.io import imshow\n",
    "# import wandb\n",
    "import matplotlib.pyplot as plt \n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torchmetrics\n",
    "import json\n",
    "\n",
    "##################\n",
    "## load configs ##\n",
    "##################\n",
    "\n",
    "config_path = os.path.join(os.getcwd(), 'configs.json')\n",
    "with open(config_path, 'r') as config_file:\n",
    "    configs = json.load(config_file)\n",
    "\n",
    "# load paths configs dictionary\n",
    "config_paths = configs.get('paths', {}) \n",
    "\n",
    "# assign paths\n",
    "palsa_shapefile = config_paths.get('palsa_shapefile') \n",
    "parent_dir = config_paths.get('data') \n",
    "rgb_dir = os.path.join(parent_dir, 'rgb')\n",
    "hs_dir = os.path.join(parent_dir, 'hs')\n",
    "dem_dir = os.path.join(parent_dir, 'dem')\n",
    "labels_file = os.path.join(parent_dir, 'palsa_labels.csv')\n",
    "\n",
    "# load hyperparams configs dictionary\n",
    "config_hyperparams = configs.get('hyperparams', {}) \n",
    "\n",
    "# assign hyperparams\n",
    "n_samples = config_hyperparams.get('n_samples')\n",
    "batch_size = config_hyperparams.get('batch_size')\n",
    "num_epochs = config_hyperparams.get('num_epochs')\n",
    "lr = config_hyperparams.get('lr')\n",
    "lr_gamma = config_hyperparams.get('lr_gamma')\n",
    "weight_decay = config_hyperparams.get('weight_decay')\n",
    "\n",
    "# load data configs dictionary\n",
    "config_data = configs.get('data', {}) \n",
    "\n",
    "# assign data configs\n",
    "im_size = config_data.get('im_size')\n",
    "min_palsa_positive_samples = config_data.get('min_palsa_positive_samples')\n",
    "low_pals_in_val = config_data.get('low_pals_in_val')\n",
    "augment = config_data.get('augment')\n",
    "normalize = config_data.get('normalize')\n",
    "depth_layer = config_data.get('depth_layer')\n",
    "\n",
    "##########################\n",
    "# log hyperparams to w&b #\n",
    "##########################\n",
    "\n",
    "# run = wandb.init(\n",
    "#     # Set the project where this run will be logged\n",
    "#     project=\"VGG_CAMs\",\n",
    "#     # Track hyperparameters and run metadata\n",
    "#     config={\n",
    "#         \"learning_rate\": lr,\n",
    "#         \"lr_gamma\": lr_gamma,\n",
    "#         \"epochs\": num_epochs,\n",
    "#         \"batch_size\": batch_size,\n",
    "#         \"n_samples\": n_samples,\n",
    "#         \"weight_decay\": weight_decay,\n",
    "#         \"im_size\": im_size,\n",
    "#         \"min_palsa_positive_samples\": min_palsa_positive_samples,\n",
    "#         \"augment\": augment,\n",
    "#         \"normalize\": normalize,\n",
    "#         \"low_pals_in_val\": low_pals_in_val,\n",
    "#         \"depth_layer\": depth_layer\n",
    "#             }#,\n",
    "#     #tags=[]\n",
    "# )\n",
    "\n",
    "#########################\n",
    "# configure dataloaders #\n",
    "#########################\n",
    "\n",
    "train_files, val_files = filter_dataset(labels_file, augment, min_palsa_positive_samples, low_pals_in_val, n_samples)\n",
    "\n",
    "# choose depth data based on configs\n",
    "depth_dir = hs_dir if depth_layer == \"hs\" else dem_dir\n",
    "\n",
    "# Create the datasets and data loaders\n",
    "train_dataset = ImageDataset(depth_dir, rgb_dir, train_files, im_size, normalize)\n",
    "val_dataset = ImageDataset(depth_dir, rgb_dir, val_files, im_size, normalize)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "################\n",
    "# define model #\n",
    "################\n",
    "\n",
    "model = model_4D()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=lr_gamma)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "#######################\n",
    "# model training loop #\n",
    "#######################\n",
    "\n",
    "# define metrics\n",
    "Accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "F1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=2)\n",
    "Recall = torchmetrics.Recall(task=\"multiclass\", average=\"micro\", num_classes=2)\n",
    "\n",
    "max_val_F1 = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('EPOCH: ',epoch+1)\n",
    "\n",
    "    ############\n",
    "    # training #\n",
    "    ############\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):     \n",
    "\n",
    "        # load images and labels \n",
    "        images = Variable(images).to(device)  \n",
    "        labels = Variable(labels.long()).to(device)  \n",
    "\n",
    "        # train batch   \n",
    "        outputs = model(images) \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "\n",
    "        # update metrics\n",
    "        train_loss = loss.item()\n",
    "        train_Accuracy = Accuracy(outputs.softmax(dim=-1), labels)\n",
    "        train_Recall = Recall(outputs.softmax(dim=-1), labels)\n",
    "        train_F1 = F1(outputs.softmax(dim=-1), labels)\n",
    "\n",
    "    ##############\n",
    "    # validation #\n",
    "    ##############\n",
    "\n",
    "    running_val_F1 = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(val_loader):  \n",
    "\n",
    "            # load images and labels \n",
    "            images = Variable(images).to(device)  \n",
    "            labels = Variable(labels.long()).to(device)  \n",
    "            outputs = model(images) \n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            # update metrics\n",
    "            val_loss = loss.item()\n",
    "            val_Accuracy = Accuracy(outputs.softmax(dim=-1), labels)\n",
    "            val_Recall = Recall(outputs.softmax(dim=-1), labels)\n",
    "\n",
    "            # handle F1 separately for best model selection\n",
    "            f1 = F1(outputs.softmax(dim=-1), labels)\n",
    "            running_val_F1.append(f1.detach().cpu().numpy())\n",
    "            val_F1 = f1\n",
    "\n",
    "    # lr scheduler step \n",
    "    scheduler.step()\n",
    "\n",
    "    # update current best model\n",
    "    if np.mean(running_val_F1) > max_val_F1:\n",
    "        best_model = model.state_dict()\n",
    "        max_val_F1 = np.mean(running_val_F1)\n",
    "\n",
    "# # after all epochs, save the best model as an artifact to wandb\n",
    "# torch.save(best_model, '/home/nadjaflechner/models/model.pth')\n",
    "# artifact = wandb.Artifact('model', type='model')\n",
    "# artifact.add_file('/home/nadjaflechner/models/model.pth')\n",
    "# run.log_artifact(artifact)\n",
    "\n",
    "#################\n",
    "# generate CAMs #\n",
    "#################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0., dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "tensie1 = torch.Tensor([[\n",
    "    [1,2,3,4],\n",
    "    [1,2,3,4],\n",
    "    [1,2,3,4],\n",
    "    [1,2,3,4]\n",
    "]])\n",
    "tensie2 = torch.cat((tensie1, tensie1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.5000]],\n",
       "\n",
       "        [[2.5000]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pool(tensie2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensie1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "palsa_env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
