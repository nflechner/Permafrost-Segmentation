{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE FOR CALCULATING DATASET-WIDE MEAN AND STD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# RGB #\n",
    "#######\n",
    "\n",
    "import os\n",
    "import rasterio \n",
    "import numpy as np\n",
    "\n",
    "dir = \"/Users/nadja/Documents/UU/Thesis/Data/TINYsampleFINAL/tinydataset/rgb/\"\n",
    "all_rgb = os.listdir(dir)\n",
    "all_rgb = [file for file in all_rgb if not file.endswith('aug.tif')]\n",
    "\n",
    "img_means_sum = np.array([0.0,0.0,0.0])\n",
    "\n",
    "for img in all_rgb:\n",
    "    with rasterio.open(os.path.join(dir, img)) as img:\n",
    "        img = img.read()\n",
    "    img_means_sum += img.mean(axis=(1,2))\n",
    "\n",
    "means = img_means_sum / len(all_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# hs/dem #\n",
    "##########\n",
    "\n",
    "import os\n",
    "import rasterio \n",
    "import numpy as np\n",
    "\n",
    "dir = \"/Users/nadja/Documents/UU/Thesis/Data/TINYsampleFINAL/tinydataset/dem/\"\n",
    "all_rgb = os.listdir(dir)\n",
    "all_rgb = [file for file in all_rgb if not file.endswith('aug.tif')]\n",
    "\n",
    "img_means_sum = np.array([0.0])\n",
    "\n",
    "for img in all_rgb:\n",
    "    with rasterio.open(os.path.join(dir, img)) as img:\n",
    "        img = img.read()\n",
    "    img_means_sum += img.mean()\n",
    "\n",
    "means = img_means_sum / len(all_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messing around: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# Imports #\n",
    "############\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from utils import ImageDataset, SaveFeatures, filter_dataset, accuracy, imshow_transform\n",
    "from custom_model import model_4D\n",
    "from torch.autograd import Variable\n",
    "# from skimage.transform import resize\n",
    "# from skimage.io import imshow\n",
    "# import wandb\n",
    "import matplotlib.pyplot as plt \n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import json\n",
    "from torchmetrics import functional \n",
    "\n",
    "##################\n",
    "## load configs ##\n",
    "##################\n",
    "\n",
    "config_path = os.path.join(os.getcwd(), 'configs.json')\n",
    "with open(config_path, 'r') as config_file:\n",
    "    configs = json.load(config_file)\n",
    "\n",
    "# load paths configs dictionary\n",
    "config_paths = configs.get('paths', {}) \n",
    "\n",
    "# assign paths\n",
    "palsa_shapefile = config_paths.get('palsa_shapefile') \n",
    "parent_dir = config_paths.get('data') \n",
    "rgb_dir = os.path.join(parent_dir, 'rgb')\n",
    "hs_dir = os.path.join(parent_dir, 'hs')\n",
    "dem_dir = os.path.join(parent_dir, 'dem')\n",
    "labels_file = os.path.join(parent_dir, 'palsa_labels.csv')\n",
    "\n",
    "# load hyperparams configs dictionary\n",
    "config_hyperparams = configs.get('hyperparams', {}) \n",
    "\n",
    "# assign hyperparams\n",
    "n_samples = config_hyperparams.get('n_samples')\n",
    "batch_size = config_hyperparams.get('batch_size')\n",
    "num_epochs = config_hyperparams.get('num_epochs')\n",
    "lr = config_hyperparams.get('lr')\n",
    "lr_gamma = config_hyperparams.get('lr_gamma')\n",
    "weight_decay = config_hyperparams.get('weight_decay')\n",
    "\n",
    "# load data configs dictionary\n",
    "config_data = configs.get('data', {}) \n",
    "\n",
    "# assign data configs\n",
    "im_size = config_data.get('im_size')\n",
    "min_palsa_positive_samples = config_data.get('min_palsa_positive_samples')\n",
    "low_pals_in_val = config_data.get('low_pals_in_val')\n",
    "augment = config_data.get('augment')\n",
    "normalize = config_data.get('normalize')\n",
    "depth_layer = config_data.get('depth_layer')\n",
    "\n",
    "##########################\n",
    "# log hyperparams to w&b #\n",
    "##########################\n",
    "\n",
    "# run = wandb.init(\n",
    "#     # Set the project where this run will be logged\n",
    "#     project=\"VGG_CAMs\",\n",
    "#     # Track hyperparameters and run metadata\n",
    "#     config={\n",
    "#         \"learning_rate\": lr,\n",
    "#         \"lr_gamma\": lr_gamma,\n",
    "#         \"epochs\": num_epochs,\n",
    "#         \"batch_size\": batch_size,\n",
    "#         \"n_samples\": n_samples,\n",
    "#         \"weight_decay\": weight_decay,\n",
    "#         \"im_size\": im_size,\n",
    "#         \"min_palsa_positive_samples\": min_palsa_positive_samples,\n",
    "#         \"augment\": augment,\n",
    "#         \"normalize\": normalize,\n",
    "#         \"low_pals_in_val\": low_pals_in_val,\n",
    "#         \"depth_layer\": depth_layer\n",
    "#             }#,\n",
    "#     #tags=[]\n",
    "# )\n",
    "\n",
    "#########################\n",
    "# configure dataloaders #\n",
    "#########################\n",
    "\n",
    "train_files, val_files = filter_dataset(labels_file, augment, min_palsa_positive_samples, low_pals_in_val, n_samples)\n",
    "\n",
    "# choose depth data based on configs\n",
    "depth_dir = hs_dir if depth_layer == \"hs\" else dem_dir\n",
    "\n",
    "# Create the datasets and data loaders\n",
    "train_dataset = ImageDataset(depth_dir, rgb_dir, train_files, im_size, normalize)\n",
    "val_dataset = ImageDataset(depth_dir, rgb_dir, val_files, im_size, normalize)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "################\n",
    "# define model #\n",
    "################\n",
    "\n",
    "model = model_4D()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=lr_gamma)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "#################\n",
    "# training loop #\n",
    "#################\n",
    "\n",
    "# adapted from https://github.com/tony-mtz/CAM/blob/master/network/net.py\n",
    "\n",
    "mean_train_losses = []\n",
    "mean_val_losses = []\n",
    "\n",
    "mean_train_acc = []\n",
    "mean_val_acc = []\n",
    "\n",
    "max_val_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('EPOCH: ',epoch+1)\n",
    "\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    train_batch_count = 0\n",
    "\n",
    "    # train one epoch\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):     \n",
    "\n",
    "        # load images and labels \n",
    "        images = Variable(images).to(device)  \n",
    "        labels = Variable(labels.long()).to(device)  \n",
    "\n",
    "        # train batch   \n",
    "        outputs = model(images) \n",
    "        # optimizer.zero_grad()\n",
    "        # loss = loss_function(outputs, labels)\n",
    "        # loss.backward()\n",
    "        # optimizer.step()  \n",
    "\n",
    "        # calculate loss and accuracy\n",
    "        train_acc.append(accuracy(outputs, labels.long()))\n",
    "\n",
    "        custom_acc = accuracy(outputs, labels.long())\n",
    "        torch_acc = functional.accuracy(outputs, labels, task=\"multiclass\", num_classes=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "palsa_env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
