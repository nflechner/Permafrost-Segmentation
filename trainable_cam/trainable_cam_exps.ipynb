{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# Imports #\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from utils import ImageDataset, SaveFeatures, accuracy, imshow_transform\n",
    "from custom_model import model_4D\n",
    "from torch.autograd import Variable\n",
    "# from skimage.transform import resize\n",
    "# from skimage.io import imshow\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt \n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "###################\n",
    "# Hyperparameters #\n",
    "\n",
    "n_samples = 10\n",
    "n_samples_train = int(round(n_samples*0.8))\n",
    "n_samples_val = int(round(n_samples*0.2))\n",
    "batch_size = 2\n",
    "current_computer =   \"macbook\" # \"ubuntu\" \n",
    "layers_to_freeze = 0\n",
    "lr = 0.0001\n",
    "weight_decay=0.04\n",
    "num_epochs = 1\n",
    "im_size = 200\n",
    "min_palsa_positive_samples = 0\n",
    "\n",
    "\n",
    "##########################\n",
    "# log hyperparams to w&b #\n",
    "\n",
    "# run = wandb.init(\n",
    "#     # Set the project where this run will be logged\n",
    "#     project=\"VGG_CAMs\",\n",
    "#     # Track hyperparameters and run metadata\n",
    "#     config={\n",
    "#         \"learning_rate\": lr,\n",
    "#         \"epochs\": num_epochs,\n",
    "#         \"batch_size\": batch_size,\n",
    "#         \"n_samples\": n_samples,\n",
    "#         \"layers_to_freeze\": layers_to_freeze,\n",
    "#         \"weight_decay\": weight_decay,\n",
    "#         \"im_size\": im_size,\n",
    "#         \"min_palsa_positive_samples\": min_palsa_positive_samples\n",
    "#     },\n",
    "#     tags=['4D', 'LRScheduler', 'MSELoss', 'TrainFromScratch']\n",
    "# )\n",
    "\n",
    "#############\n",
    "# Load data #\n",
    "\n",
    "if current_computer == \"ubuntu\":\n",
    "    hs_dir = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/hs'\n",
    "    RGB_dir = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/rgb'\n",
    "    labels_file = f'/home/nadjaflechner/Palsa_data/cropped_hillshade_{im_size}m/palsa_labels.csv'\n",
    "elif current_computer == \"macbook\":\n",
    "    hs_dir = '/Users/nadja/Documents/UU/Thesis/Data/200m/hs'\n",
    "    RGB_dir = '/Users/nadja/Documents/UU/Thesis/Data/200m/rgb'\n",
    "    labels_file = '/Users/nadja/Documents/UU/Thesis/Data/200m/palsa_labels.csv'\n",
    "\n",
    "# Load the labels from the CSV file\n",
    "if min_palsa_positive_samples > 0:\n",
    "    labels_df = pd.read_csv(labels_file, index_col=0)\n",
    "    drop_range = labels_df[ (labels_df['palsa_percentage'] > 0) & (labels_df['palsa_percentage'] < min_palsa_positive_samples) ].index\n",
    "\n",
    "    labels_df.drop(drop_range, inplace=True)\n",
    "    labels_df = labels_df.head(n_samples)\n",
    "else: \n",
    "    labels_df = pd.read_csv(labels_file, index_col=0).head(n_samples)\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df = labels_df.head(n_samples_train)\n",
    "val_df = labels_df.drop(train_df.index)\n",
    "\n",
    "# Create the datasets and data loaders\n",
    "train_dataset = ImageDataset(hs_dir, RGB_dir, train_df, im_size)\n",
    "val_dataset = ImageDataset(hs_dir, RGB_dir, val_df, im_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Define model \n",
    "\n",
    "model = model_4D()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.92)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  1\n",
      "tensor(0.0984)\n",
      "tensor(0.8288, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1913)\n",
      "tensor(0.6366, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4569)\n",
      "tensor(0.7437, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7597)\n",
      "tensor(0.6958, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# Training loop #\n",
    "\n",
    "# adapted from https://github.com/tony-mtz/CAM/blob/master/network/net.py\n",
    "\n",
    "mean_train_losses = []\n",
    "mean_val_losses = []\n",
    "\n",
    "mean_train_acc = []\n",
    "mean_val_acc = []\n",
    "\n",
    "max_val_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('EPOCH: ',epoch+1)\n",
    "\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    train_batch_count = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):     \n",
    "\n",
    "        # load images and labels \n",
    "        images = Variable(images).to(device)  \n",
    "        percent_labels = Variable(labels[0].long()/100).to(device)  \n",
    "        binary_labels = Variable(labels[1].long()).to(device)  \n",
    "\n",
    "        # prep feature saving\n",
    "        lastconv = SaveFeatures(model.features[-4])\n",
    "\n",
    "        # train batch   \n",
    "        outputs = model(images) \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # WEIGH THE LOSS BY THE BINARY LABELS \n",
    "\n",
    "        lastconv_act = lastconv.features.cpu().detach()\n",
    "        palsa_maps = lastconv_act[:, 0, :, :]\n",
    "        act_map_size = palsa_maps.shape[1] * palsa_maps.shape[2] \n",
    "        activation_threshold = 0.2\n",
    "        pixels_activated = torch.where(palsa_maps > activation_threshold, 1, 0)\n",
    "        percent_activated = torch.sum(pixels_activated, dim = (1,2)) / act_map_size\n",
    "\n",
    "        percent_loss = torch.sum((percent_labels - percent_activated)**2)\n",
    "        regular_loss = loss_function(outputs, binary_labels)\n",
    "        loss = percent_loss + regular_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "\n",
    "        # calculate loss and accuracy\n",
    "        train_acc.append(accuracy(outputs, binary_labels.long()))\n",
    "        running_loss += loss.item()\n",
    "        train_batch_count += 1\n",
    "\n",
    "    model.eval()\n",
    "    val_batch_count = 0\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(val_loader):     \n",
    "\n",
    "            # load images and labels \n",
    "            images = Variable(images).to(device)  \n",
    "            percent_labels = Variable(labels[0].long()/100).to(device)  \n",
    "            binary_labels = Variable(labels[1].long()).to(device)  \n",
    "            outputs = model(images) \n",
    "            loss = loss_function(outputs, binary_labels)\n",
    "\n",
    "            val_acc.append(accuracy(outputs, binary_labels))\n",
    "            val_running_loss += loss.item()\n",
    "            val_batch_count +=1\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # update losses and accuracies \n",
    "    mean_train_acc.append(np.mean(train_acc))\n",
    "    mean_val_acc.append(np.mean(val_acc))\n",
    "    mean_train_losses.append(running_loss/train_batch_count)\n",
    "    mean_val_losses.append(val_running_loss/val_batch_count)\n",
    "\n",
    "    wandb.log({\"train_accuracy\": np.mean(train_acc)})\n",
    "    wandb.log({\"val_accuracy\": np.mean(val_acc)})\n",
    "    wandb.log({\"train_loss\": running_loss/train_batch_count})\n",
    "    wandb.log({\"val_loss\": val_running_loss/val_batch_count})\n",
    "\n",
    "    if np.mean(val_acc) > max_val_acc:\n",
    "        best_model = model.state_dict()\n",
    "        max_val_acc = np.mean(val_acc)\n",
    "\n",
    "torch.save(best_model, '/home/nadjaflechner/models/model.pth')\n",
    "artifact = wandb.Artifact('model', type='model')\n",
    "artifact.add_file('/home/nadjaflechner/models/model.pth')\n",
    "run.log_artifact(artifact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# generating CAMs #\n",
    "\n",
    "#change batch size to 1 to grab one image at a time\n",
    "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, \n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "# Load best model to produce CAMs with\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "# Save 10 palsa images\n",
    "palsa_imgs = 0\n",
    "for palsa_cam in range(100):\n",
    "    im, (percent_label, binary_label) = next(iter(valid_loader))\n",
    "\n",
    "    #get the last convolution\n",
    "    sf = SaveFeatures(model.features[-4])\n",
    "    model.eval()\n",
    "\n",
    "    if binary_label == 1:\n",
    "        palsa_imgs+= 1\n",
    "        im = Variable(im).to(device)\n",
    "        outputs = model(im).to(device)\n",
    "        res = torch.argmax(outputs.data).cpu().detach().numpy()\n",
    "\n",
    "        # generate CAM\n",
    "        sf.remove()\n",
    "        arr = sf.features.cpu().detach().numpy()\n",
    "        arr1 = arr[0]\n",
    "        ans_nopalsa = np.dot(np.rollaxis(arr1,0,3), [1,0])\n",
    "        ans_palsa = np.dot(np.rollaxis(arr1,0,3), [0,1])\n",
    "\n",
    "        if res==1:\n",
    "            CAM = resize(ans_palsa, (im_size*2,im_size*2))\n",
    "        else:\n",
    "            CAM = resize(ans_nopalsa, (im_size*2,im_size*2))\n",
    "\n",
    "        # Plot image with CAM\n",
    "        cpu_img = im.squeeze().cpu().detach().permute(1,2,0).long().numpy()\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,7))\n",
    "\n",
    "        ax1.imshow(cpu_img)\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        ax1.set_title(f'original image')\n",
    "\n",
    "        ax2.imshow(cpu_img)\n",
    "        ax2.imshow(CAM, alpha=.4, cmap='jet')\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        ax2.set_title('image with CAM')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        wandb.log({'generated_CAM': fig})\n",
    "\n",
    "    if palsa_imgs == 20:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "palsa_env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
